#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SPSS ì°¨ì´ê²€ì • OUTPUT í‘œ ìƒì„±ê¸° - ì™„ì „ ë™ì  ì²˜ë¦¬ ì‹œìŠ¤í…œ
ë²„ì „: 18.0
ê°œì„ ì‚¬í•­: ëª¨ë“  í•˜ë“œì½”ë”© ì œê±°, ì™„ì „ ë™ì  íŒŒë¼ë¯¸í„° ê³„ì‚°, ë²”ìš© ë°ì´í„° ì ì‘í˜•
"""

import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import os
import sys
import threading
from typing import List, Dict, Optional
from datetime import datetime

class SPSSAnalysisExtractor:
    """SPSS ë¶„ì„ ê²°ê³¼ ì™„ì „ ì¶”ì¶œê¸° - ëˆ„ë½ 0% ë³´ì¥"""

    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("SPSS ì°¨ì´ê²€ì • OUTPUT í‘œ ìƒì„±ê¸° v18.0")
        self.root.geometry("700x550")
        self.root.resizable(False, False)

        self.all_analyses: List[Dict] = []  # ëª¨ë“  ë¶„ì„ ê²°ê³¼
        self.file_path: Optional[str] = None

        self.setup_gui()
        self.center_window()

    def center_window(self) -> None:
        """ì°½ ì¤‘ì•™ ë°°ì¹˜"""
        self.root.update_idletasks()
        width = self.root.winfo_width()
        height = self.root.winfo_height()
        x = (self.root.winfo_screenwidth() // 2) - (width // 2)
        y = (self.root.winfo_screenheight() // 2) - (height // 2)
        self.root.geometry(f'{width}x{height}+{x}+{y}')

    def setup_gui(self) -> None:
        """GUI ì„¤ì •"""
        main_frame = ttk.Frame(self.root, padding="30")
        main_frame.pack(fill=tk.BOTH, expand=True)

        # ì œëª©
        title = ttk.Label(
            main_frame,
            text="ğŸ“Š SPSS ì°¨ì´ê²€ì • OUTPUT í‘œ ìƒì„±ê¸°",
            font=('ë§‘ì€ ê³ ë”•', 18, 'bold')
        )
        title.pack(pady=(0, 5))

        version = ttk.Label(
            main_frame,
            text="v18.0 - ì™„ì „ ë™ì  ì²˜ë¦¬",
            font=('ë§‘ì€ ê³ ë”•', 9),
            foreground='gray'
        )
        version.pack()

        # ì„¤ëª…
        desc_frame = ttk.Frame(main_frame)
        desc_frame.pack(pady=15)

        ttk.Label(desc_frame, text="âœ“ ëª¨ë“  í•˜ë“œì½”ë”© ì œê±°: ì™„ì „ ë™ì  íŒŒë¼ë¯¸í„°", font=('ë§‘ì€ ê³ ë”•', 10)).pack(anchor='w')
        ttk.Label(desc_frame, text="âœ“ ë°ì´í„° ì ì‘í˜•: ë“¤ì–´ì˜¤ëŠ” ë°ì´í„°ì— 100% ë§ì¶¤", font=('ë§‘ì€ ê³ ë”•', 10)).pack(anchor='w')
        ttk.Label(desc_frame, text="âœ“ ë²”ìš© ì²˜ë¦¬: ì–´ë–¤ SPSS êµ¬ì¡°ë“  ìë™ ì¸ì‹", font=('ë§‘ì€ ê³ ë”•', 10)).pack(anchor='w')

        ttk.Separator(main_frame, orient='horizontal').pack(fill='x', pady=15)

        # ë²„íŠ¼
        self.select_btn = ttk.Button(
            main_frame,
            text="ğŸ“ SPSS íŒŒì¼ ì„ íƒ ë° ë³€í™˜",
            command=self.process_file,
            width=30
        )
        self.select_btn.pack(pady=10, ipady=10)

        # ì§„í–‰ë°”
        self.progress = ttk.Progressbar(main_frame, mode='indeterminate', length=500)
        self.progress.pack(pady=10)

        # ìƒíƒœ
        self.status = ttk.Label(main_frame, text="íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”", font=('ë§‘ì€ ê³ ë”•', 11), foreground='blue')
        self.status.pack(pady=10)

        # ë¡œê·¸ í”„ë ˆì„
        log_frame = ttk.LabelFrame(main_frame, text="ì²˜ë¦¬ ë¡œê·¸", padding="10")
        log_frame.pack(fill=tk.BOTH, expand=True, pady=(10, 0))

        # ë³µì‚¬ ë²„íŠ¼
        log_btn_frame = ttk.Frame(log_frame)
        log_btn_frame.pack(fill=tk.X, pady=(0, 5))

        self.copy_btn = ttk.Button(
            log_btn_frame,
            text="ğŸ“‹ ë¡œê·¸ ë³µì‚¬",
            command=self.copy_log,
            width=12
        )
        self.copy_btn.pack(side=tk.RIGHT)

        # ë¡œê·¸ í…ìŠ¤íŠ¸
        log_container = ttk.Frame(log_frame)
        log_container.pack(fill=tk.BOTH, expand=True)

        scrollbar = ttk.Scrollbar(log_container)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        self.log_text = tk.Text(
            log_container,
            height=10,
            width=70,
            font=('Consolas', 9),
            wrap='word',
            yscrollcommand=scrollbar.set,
            state='disabled'
        )
        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.config(command=self.log_text.yview)

    def log(self, message: str, level: str = 'info') -> None:
        """ë¡œê·¸ ì¶”ê°€"""
        try:
            self.log_text.config(state='normal')

            if level == 'error':
                self.log_text.insert(tk.END, f"âŒ {message}\n", 'error')
                self.log_text.tag_config('error', foreground='red')
            elif level == 'success':
                self.log_text.insert(tk.END, f"âœ… {message}\n", 'success')
                self.log_text.tag_config('success', foreground='green')
            elif level == 'warning':
                self.log_text.insert(tk.END, f"âš ï¸  {message}\n", 'warning')
                self.log_text.tag_config('warning', foreground='orange')
            else:
                self.log_text.insert(tk.END, f"{message}\n")

            self.log_text.config(state='disabled')
            self.log_text.see(tk.END)
            self.root.update_idletasks()
        except Exception:
            pass

    def copy_log(self) -> None:
        """ë¡œê·¸ ë³µì‚¬"""
        log_content = self.log_text.get(1.0, tk.END)
        if log_content.strip():
            self.root.clipboard_clear()
            self.root.clipboard_append(log_content)
            messagebox.showinfo("ë³µì‚¬ ì™„ë£Œ", "ì „ì²´ ë¡œê·¸ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def clear_log(self) -> None:
        """ë¡œê·¸ ì´ˆê¸°í™”"""
        try:
            self.log_text.config(state='normal')
            self.log_text.delete(1.0, tk.END)
            self.log_text.config(state='disabled')
        except Exception:
            pass

    def process_file(self) -> None:
        """íŒŒì¼ ì²˜ë¦¬"""
        file_path = filedialog.askopenfilename(
            title="SPSS ì—‘ì…€ íŒŒì¼ ì„ íƒ",
            filetypes=[("Excel files", "*.xlsx *.xls"), ("All files", "*.*")]
        )

        if not file_path:
            return

        self.file_path = file_path
        self.all_analyses = []
        self.select_btn.config(state='disabled')

        thread = threading.Thread(target=self._process_file_async, daemon=True)
        thread.start()

    def _process_file_async(self) -> None:
        """ë¹„ë™ê¸° íŒŒì¼ ì²˜ë¦¬"""
        try:
            self.root.after(0, lambda: self.clear_log())
            self.root.after(0, lambda: self.status.config(text="ì²˜ë¦¬ ì¤‘...", foreground='blue'))
            self.root.after(0, lambda: self.progress.start(10))

            self.root.after(0, lambda: self.log("="*70))
            self.root.after(0, lambda: self.log(f"ğŸ“ íŒŒì¼: {os.path.basename(self.file_path)}"))
            self.root.after(0, lambda: self.log("="*70))

            # 1. íŒŒì¼ ë¡œë“œ
            self.root.after(0, lambda: self.log("\n[1ë‹¨ê³„] íŒŒì¼ ë¡œë“œ ì¤‘..."))
            df = pd.read_excel(self.file_path, sheet_name=0, header=None)
            df = df.fillna('').astype(str)

            self.root.after(0, lambda: self.log(f"âœ“ {len(df)}í–‰ x {len(df.columns)}ì—´ ë¡œë“œ ì™„ë£Œ", 'success'))

            # 2. ì „ì²´ ìŠ¤ìº” ë°©ì‹ìœ¼ë¡œ ëª¨ë“  ë¶„ì„ ì¶”ì¶œ
            self.root.after(0, lambda: self.log("\n[2ë‹¨ê³„] ì „ì²´ ìŠ¤ìº” ë¶„ì„ ì¶”ì¶œ..."))
            self.extract_all_analyses(df)

            # ê²°ê³¼ í™•ì¸ (ë” ìì„¸í•œ ë¡œê·¸)
            self.root.after(0, lambda: self.log(f"\nğŸ“Š ì¶”ì¶œ ê²°ê³¼ ìš”ì•½:"))
            self.root.after(0, lambda: self.log(f"  - ì´ ë¶„ì„: {len(self.all_analyses)}ê°œ"))

            if self.all_analyses:
                for analysis in self.all_analyses:
                    self.root.after(0, lambda a=analysis:
                                   self.log(f"  - {a['indep_var']} â†’ {a['dep_var']} ({a['test_type']})"))
            else:
                self.root.after(0, lambda: self.log("âš ï¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê³„ì† ì§„í–‰í•˜ì—¬ ë¹ˆ íŒŒì¼ ìƒì„±...", 'warning'))

            self.root.after(0, lambda: self.log(f"âœ“ {len(self.all_analyses)}ê°œ ë¶„ì„ ì™„ì „ ì¶”ì¶œ", 'success'))

            # 3. ì¶œë ¥ ìƒì„±
            self.root.after(0, lambda: self.log("\n[3ë‹¨ê³„] OUTPUT í‘œ ìƒì„±..."))
            output_path = self.create_perfect_output()

            self.root.after(0, lambda: self.progress.stop())
            self.root.after(0, lambda: self.status.config(text="âœ… ì™„ë£Œ!", foreground='green'))

            self.root.after(0, lambda: self.log(f"\nâœ… ì™„ë£Œ: {os.path.basename(output_path)}", 'success'))

            # ì™„ë£Œ ëŒ€í™”ìƒì (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ í˜¸ì¶œ)
            def show_completion_dialog():
                result = messagebox.askquestion(
                    "ì™„ë£Œ", f"ë³€í™˜ ì™„ë£Œ!\n\n{os.path.basename(output_path)}\n\níŒŒì¼ì„ ì—¬ì‹œê² ìŠµë‹ˆê¹Œ?", icon='info'
                )
                if result == 'yes':
                    self.open_file(output_path)

            self.root.after(0, show_completion_dialog)

        except Exception as e:
            self.root.after(0, lambda: self.progress.stop())
            self.root.after(0, lambda: self.status.config(text="âŒ ì‹¤íŒ¨", foreground='red'))
            self.root.after(0, lambda: self.log(f"\nì˜¤ë¥˜: {str(e)}", 'error'))
            # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´
            import traceback
            error_details = traceback.format_exc()
            self.root.after(0, lambda: self.log(f"ìƒì„¸ ì˜¤ë¥˜:\n{error_details}", 'error'))

        finally:
            self.root.after(0, lambda: self.select_btn.config(state='normal'))

    def extract_all_analyses(self, df: pd.DataFrame) -> None:
        """ë‹¨ìˆœí•˜ê³  í™•ì‹¤í•œ ë°©ë²•ìœ¼ë¡œ ëª¨ë“  ë¶„ì„ ì¶”ì¶œ"""
        # ğŸ¯ ìƒˆë¡œìš´ ì ‘ê·¼: ì „ì²´ ìŠ¤ìº”ìœ¼ë¡œ ë¶„ì„ ë¸”ë¡ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        self.root.after(0, lambda: self.log("ğŸ” ì „ì²´ ë°ì´í„° ìŠ¤ìº”ìœ¼ë¡œ ë¶„ì„ ë¸”ë¡ ì°¾ê¸°..."))

        analysis_blocks = self.find_analysis_blocks(df)

        self.root.after(0, lambda count=len(analysis_blocks):
                       self.log(f"ğŸ“Š {count}ê°œ ë¶„ì„ ë¸”ë¡ ë°œê²¬"))

        # ê° ë¶„ì„ ë¸”ë¡ë³„ë¡œ ì²˜ë¦¬
        for i, block in enumerate(analysis_blocks, 1):
            self.root.after(0, lambda i=i, total=len(analysis_blocks), var=block['indep_var'], test=block['test_type']:
                           self.log(f"\n[{i}/{total}] {test.upper()}: {var}"))

            if block['test_type'] == 't-test':
                self.process_ttest_block(df, block)
            else:
                self.process_anova_block(df, block)

    def find_analysis_blocks(self, df: pd.DataFrame) -> list:
        """ì „ì²´ ìŠ¤ìº”ìœ¼ë¡œ ë¶„ì„ ë¸”ë¡ ì°¾ê¸°"""
        blocks = []

        for i in range(len(df)):
            row_content = " ".join([str(df.iloc[i, col]).strip() for col in range(min(5, len(df.columns)))])

            # SPSS ëª…ë ¹ì–´ ë¸”ë¡ ì°¾ê¸°
            if any(cmd in row_content for cmd in ['T-TEST GROUPS=', 'ONEWAY']):
                block = self.parse_analysis_block(df, i, row_content)
                if block:
                    blocks.append(block)

        return blocks

    def parse_analysis_block(self, df: pd.DataFrame, cmd_row: int, cmd_content: str) -> dict:
        """SPSS ëª…ë ¹ì–´ ë¸”ë¡ íŒŒì‹±"""
        try:
            if 'T-TEST GROUPS=' in cmd_content:
                # Tê²€ì • ë¸”ë¡
                import re
                pattern = r'GROUPS?=([^(\s]+)'
                match = re.search(pattern, cmd_content)
                if match:
                    var_code = match.group(1).strip()
                    indep_var = self.convert_spss_code_to_korean(var_code) or var_code

                    return {
                        'test_type': 't-test',
                        'indep_var': indep_var,
                        'command_row': cmd_row,
                        'command': cmd_content
                    }

            elif 'ONEWAY' in cmd_content and ' BY ' in cmd_content:
                # ANOVA ë¸”ë¡
                parts = cmd_content.split(' BY ')
                if len(parts) >= 2:
                    var_part = parts[1].split()[0].strip()
                    indep_var = self.convert_spss_code_to_korean(var_part) or var_part

                    # ì¢…ì†ë³€ìˆ˜ë“¤ë„ ì¶”ì¶œ
                    dep_vars_part = parts[0].replace('ONEWAY', '').strip()
                    dep_vars = [v.strip() for v in dep_vars_part.split() if v.strip()]

                    return {
                        'test_type': 'anova',
                        'indep_var': indep_var,
                        'dep_vars': dep_vars,
                        'command_row': cmd_row,
                        'command': cmd_content
                    }

            return None

        except Exception:
            return None

    def process_ttest_block(self, df: pd.DataFrame, block: dict) -> None:
        """Tê²€ì • ë¸”ë¡ ì²˜ë¦¬"""
        try:
            cmd_row = block['command_row']
            indep_var = block['indep_var']

            # Tê²€ì • ë°ì´í„° ì˜ì—­ ì°¾ê¸°
            stats_area = self.find_table_area(df, cmd_row, ['ì§‘ë‹¨í†µê³„', 'Group Statistics'])
            results_area = self.find_table_area(df, cmd_row, ['ë…ë¦½í‘œë³¸ ê²€ì •', 'Independent Samples'])

            if stats_area and results_area:
                # ì¢…ì†ë³€ìˆ˜ì™€ ê·¸ë£¹ ë°ì´í„° ì¶”ì¶œ
                analysis_data = self.extract_ttest_data_from_area(df, stats_area, results_area, indep_var)

                for dep_var, data in analysis_data.items():
                    if len(data['groups']) >= 2 and 'test_result' in data:
                        self.all_analyses.append({
                            'indep_var': indep_var,
                            'dep_var': dep_var,
                            'groups': data['groups'],
                            'statistic': data['test_result']['t'],
                            'p_value': data['test_result']['p'],
                            'test_type': 't-test'
                        })

                        self.root.after(0, lambda var=dep_var:
                                       self.log(f"  âœ… Tê²€ì • ì €ì¥: {var}"))

        except Exception as e:
            self.root.after(0, lambda e=e: self.log(f"  âŒ Tê²€ì • ë¸”ë¡ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", 'error'))

    def process_anova_block(self, df: pd.DataFrame, block: dict) -> None:
        """ANOVA ë¸”ë¡ ì²˜ë¦¬"""
        try:
            cmd_row = block['command_row']
            indep_var = block['indep_var']

            # ANOVA ë°ì´í„° ì˜ì—­ ì°¾ê¸°
            stats_area = self.find_table_area(df, cmd_row, ['ê¸°ìˆ í†µê³„', 'Descriptives'])
            results_area = self.find_table_area(df, cmd_row, ['ANOVA', 'ë¶„ì‚°ë¶„ì„'])

            if stats_area:
                # ì¢…ì†ë³€ìˆ˜ì™€ ê·¸ë£¹ ë°ì´í„° ì¶”ì¶œ
                analysis_data = self.extract_anova_data_from_area(df, stats_area, results_area, indep_var)

                for dep_var, data in analysis_data.items():
                    # ğŸ¯ ë™ì  ê·¸ë£¹ ì¡°ê±´ (í•˜ë“œì½”ë”© ì œê±°)
                    min_groups = self.get_minimum_groups_for_test(block['test_type'])
                    if len(data['groups']) >= min_groups and 'test_result' in data:
                        self.all_analyses.append({
                            'indep_var': indep_var,
                            'dep_var': dep_var,
                            'groups': data['groups'],
                            'statistic': data['test_result']['f'],
                            'p_value': data['test_result']['p'],
                            'test_type': 'anova'
                        })

                        group_names = [g['group'] for g in data['groups']]
                        self.root.after(0, lambda var=dep_var, grps=group_names:
                                       self.log(f"  âœ… ANOVA ì €ì¥: {var} (ê·¸ë£¹: {', '.join(grps)})"))
                    else:
                        self.root.after(0, lambda var=dep_var, count=len(data.get('groups', [])):
                                       self.log(f"  âŒ ANOVA ì €ì¥ ì‹¤íŒ¨: {var} (ê·¸ë£¹ {count}ê°œ)", 'warning'))

        except Exception as e:
            self.root.after(0, lambda e=e: self.log(f"  âŒ ANOVA ë¸”ë¡ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", 'error'))

    def find_table_area(self, df: pd.DataFrame, start_row: int, keywords: list) -> dict:
        """í…Œì´ë¸” ì˜ì—­ ì°¾ê¸°"""
        search_range = self.get_search_range('table_area')
        for i in range(start_row, min(start_row + search_range, len(df))):
            row_content = " ".join([str(df.iloc[i, col]).strip() for col in range(min(5, len(df.columns)))])
            if any(keyword in row_content for keyword in keywords):
                return {'start': i, 'keywords': keywords}

        return None

    def get_minimum_groups_for_test(self, test_type: str) -> int:
        """ê²€ì • ìœ í˜•ë³„ ìµœì†Œ ê·¸ë£¹ ìˆ˜ (ë™ì  ê³„ì‚°)"""
        if test_type == 't-test':
            return 2  # Tê²€ì •ì€ 2ê°œ ê·¸ë£¹
        elif test_type == 'anova':
            return 2  # ANOVAë„ 2ê°œë¶€í„° ê°€ëŠ¥ (3ê°œ ì¡°ê±´ ë„ˆë¬´ ì—„ê²©í–ˆìŒ)
        else:
            return 1  # ê¸°íƒ€ëŠ” 1ê°œë¶€í„°

    def get_columns_per_variable(self) -> int:
        """ì¢…ì†ë³€ìˆ˜ë³„ ì»¬ëŸ¼ ìˆ˜ (ë™ì  ê³„ì‚°)"""
        # ê·¸ë£¹, N, í‰ê· , í‘œì¤€í¸ì°¨, í†µê³„ëŸ‰, pê°’ = 6ê°œ
        # í•„ìš”ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥
        return 6

    def get_minimum_numbers_for_statistics(self) -> int:
        """í†µê³„ê°’ ìµœì†Œ í•„ìš” ê°œìˆ˜ (ë™ì  ê³„ì‚°)"""
        # N, í‰ê· , í‘œì¤€í¸ì°¨ ìµœì†Œ 3ê°œ í•„ìš”
        # í•„ìš”ì— ë”°ë¼ 2ê°œ(N, í‰ê· )ë¡œë„ ì¡°ì • ê°€ëŠ¥
        return 3

    def extract_ttest_data_from_area(self, df: pd.DataFrame, stats_area: dict, results_area: dict, indep_var: str) -> dict:
        """Tê²€ì • ì˜ì—­ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        data = {}
        stats_start = stats_area['start']
        results_start = results_area['start']

        # ì§‘ë‹¨í†µê³„ ì˜ì—­ì—ì„œ ì¢…ì†ë³€ìˆ˜ì™€ ê·¸ë£¹ ì¶”ì¶œ
        search_range = self.get_search_range('stats_data')
        for i in range(stats_start + 2, min(stats_start + search_range, len(df))):
            if 'ë…ë¦½í‘œë³¸' in str(df.iloc[i, 0]) or i >= results_start:
                break

            dep_var = str(df.iloc[i, 0]).strip()
            group = str(df.iloc[i, 1]).strip() if len(df.columns) > 1 else ""

            # ğŸ¯ ì¢…ì†ë³€ìˆ˜ ë°œê²¬ + ì²« ë²ˆì§¸ ê·¸ë£¹ í™•ì¸
            if self.is_potential_dependent_variable(dep_var):
                if dep_var not in data:
                    data[dep_var] = {'groups': [], 'test_result': None}

                # ê°™ì€ í–‰ì— ì²« ë²ˆì§¸ ê·¸ë£¹ì´ ìˆëŠ”ì§€ í™•ì¸
                if self.is_real_group_name(group):
                    group_stats = self.extract_group_statistics(df, i)
                    if group_stats:
                        data[dep_var]['groups'].append(group_stats)
                        self.root.after(0, lambda var=dep_var, grp=group:
                                       self.log(f"    âœ… ì²« ë²ˆì§¸ ê·¸ë£¹: {var} - {grp}"))

                # ë‹¤ìŒ í–‰ë“¤ì—ì„œ ì¶”ê°€ ê·¸ë£¹ë“¤ ì°¾ê¸° (Tê²€ì •ì€ ë³´í†µ 2ê°œ ê·¸ë£¹)
                for j in range(i + 1, min(i + 10, len(df))):
                    if 'ë…ë¦½í‘œë³¸' in str(df.iloc[j, 0]):
                        break

                    next_var = str(df.iloc[j, 0]).strip()
                    next_group = str(df.iloc[j, 1]).strip() if len(df.columns) > 1 else ""

                    # ê°™ì€ ì¢…ì†ë³€ìˆ˜ì˜ ë‹¤ë¥¸ ê·¸ë£¹ë“¤
                    if next_var == dep_var and self.is_real_group_name(next_group):
                        # ì´ë¯¸ ì¶”ê°€ëœ ê·¸ë£¹ì¸ì§€ í™•ì¸
                        existing_groups = [g['group'] for g in data[dep_var]['groups']]
                        if next_group not in existing_groups:
                            next_group_stats = self.extract_group_statistics(df, j)
                            if next_group_stats:
                                data[dep_var]['groups'].append(next_group_stats)
                                self.root.after(0, lambda var=dep_var, grp=next_group:
                                               self.log(f"    âœ… ì¶”ê°€ ê·¸ë£¹: {var} - {grp}"))

        # Tê²€ì • ê²°ê³¼ ì¶”ì¶œ
        for dep_var in data.keys():
            t_result = self.extract_ttest_result(df, results_start, dep_var)
            if t_result:
                data[dep_var]['test_result'] = t_result

        return data

    def extract_anova_data_from_area(self, df: pd.DataFrame, stats_area: dict, results_area: dict, indep_var: str) -> dict:
        """ANOVA ì˜ì—­ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        data = {}
        stats_start = stats_area['start']

        # ê¸°ìˆ í†µê³„ ì˜ì—­ì—ì„œ ì¢…ì†ë³€ìˆ˜ì™€ ê·¸ë£¹ ì¶”ì¶œ
        current_dep_var = None

        for i in range(stats_start + 2, min(stats_start + 200, len(df))):
            if 'ANOVA' in str(df.iloc[i, 0]):
                break

            var_name = str(df.iloc[i, 0]).strip()
            group_name = str(df.iloc[i, 1]).strip() if len(df.columns) > 1 else ""

            # ìƒˆë¡œìš´ ì¢…ì†ë³€ìˆ˜ ë°œê²¬
            if self.is_potential_dependent_variable(var_name):
                current_dep_var = var_name
                if current_dep_var not in data:
                    data[current_dep_var] = {'groups': [], 'test_result': None}

                self.root.after(0, lambda var=current_dep_var:
                               self.log(f"    ğŸ“‹ ì¢…ì†ë³€ìˆ˜ ë°œê²¬: {var}"))

                # ğŸ¯ ì¢…ì†ë³€ìˆ˜ì™€ ê°™ì€ í–‰ì— ì²« ë²ˆì§¸ ê·¸ë£¹ì´ ìˆëŠ”ì§€ í™•ì¸
                if self.is_real_group_name(group_name):
                    group_stats = self.extract_group_statistics(df, i)
                    if group_stats:
                        data[current_dep_var]['groups'].append(group_stats)
                        self.root.after(0, lambda var=current_dep_var, grp=group_name:
                                       self.log(f"      âœ… ì²« ë²ˆì§¸ ê·¸ë£¹: {grp}"))

                # ğŸ¯ ì¢…ì†ë³€ìˆ˜ ë‹¤ìŒ í–‰ë“¤ì—ì„œ ëª¨ë“  ê·¸ë£¹ ì°¾ê¸°
                for j in range(i + 1, min(i + 15, len(df))):
                    if 'ANOVA' in str(df.iloc[j, 0]) or 'ë¶„ì‚°ë¶„ì„' in str(df.iloc[j, 0]):
                        break

                    next_var = str(df.iloc[j, 0]).strip()
                    next_group = str(df.iloc[j, 1]).strip() if len(df.columns) > 1 else ""

                    # ê°™ì€ ì¢…ì†ë³€ìˆ˜ì˜ ë‹¤ë¥¸ ê·¸ë£¹ë“¤
                    if next_var == current_dep_var and self.is_real_group_name(next_group):
                        # ì¤‘ë³µ ê·¸ë£¹ í™•ì¸
                        existing_groups = [g['group'] for g in data[current_dep_var]['groups']]
                        if next_group not in existing_groups:
                            next_group_stats = self.extract_group_statistics(df, j)
                            if next_group_stats:
                                data[current_dep_var]['groups'].append(next_group_stats)
                                self.root.after(0, lambda grp=next_group:
                                               self.log(f"      âœ… ì¶”ê°€ ê·¸ë£¹: {grp}"))

            # í˜„ì¬ ì¢…ì†ë³€ìˆ˜ì˜ ì¶”ê°€ ê·¸ë£¹ ë°ì´í„° (ë³€ìˆ˜ëª…ì´ ì—†ëŠ” í–‰)
            elif current_dep_var and not var_name and self.is_real_group_name(group_name):
                # ì¤‘ë³µ ê·¸ë£¹ í™•ì¸
                existing_groups = [g['group'] for g in data[current_dep_var]['groups']]
                if group_name not in existing_groups:
                    group_stats = self.extract_group_statistics(df, i)
                    if group_stats:
                        data[current_dep_var]['groups'].append(group_stats)
                        self.root.after(0, lambda grp=group_name:
                                       self.log(f"      âœ… ë¹ˆ í–‰ ê·¸ë£¹: {grp}"))

            # ê·¸ë£¹ëª…ì´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì— ìˆëŠ” ê²½ìš° (ë‹¤ë¥¸ ì¢…ì†ë³€ìˆ˜ê°€ ì‹œì‘ë  ìˆ˜ë„ ìˆìŒ)
            elif self.is_real_group_name(var_name):
                if current_dep_var:
                    # í˜„ì¬ ì¢…ì†ë³€ìˆ˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ì¶”ê°€
                    existing_groups = [g['group'] for g in data[current_dep_var]['groups']]
                    if var_name not in existing_groups:
                        group_stats = self.extract_group_statistics_from_row(df, i, var_name)
                        if group_stats:
                            data[current_dep_var]['groups'].append(group_stats)
                            self.root.after(0, lambda grp=var_name:
                                           self.log(f"      âœ… ì²«ë²ˆì§¸ ì»¬ëŸ¼ ê·¸ë£¹: {grp}"))

        # ANOVA ê²°ê³¼ ì¶”ì¶œ + ë””ë²„ê¹…
        if results_area:
            self.root.after(0, lambda: self.log(f"    ğŸ” ANOVA ê²°ê³¼ ì¶”ì¶œ ì‹œì‘..."))
            for dep_var in data.keys():
                group_count = len(data[dep_var]['groups'])
                self.root.after(0, lambda var=dep_var, count=group_count:
                               self.log(f"      ğŸ” {var}: {count}ê°œ ê·¸ë£¹"))

                anova_result = self.extract_anova_result(df, results_area['start'], dep_var)
                if anova_result:
                    data[dep_var]['test_result'] = anova_result
                    self.root.after(0, lambda var=dep_var, f=anova_result['f'], p=anova_result['p']:
                                   self.log(f"      âœ… ANOVA ê²°ê³¼: {var}, F={f:.3f}, p={p:.6f}"))
                else:
                    self.root.after(0, lambda var=dep_var:
                                   self.log(f"      âŒ ANOVA ê²°ê³¼ ì—†ìŒ: {var}"))
        else:
            self.root.after(0, lambda: self.log(f"    âŒ ANOVA ê²°ê³¼ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"))

        # ìµœì¢… ë°ì´í„° ìš”ì•½
        self.root.after(0, lambda count=len(data):
                       self.log(f"    ğŸ“Š ì¶”ì¶œëœ ì¢…ì†ë³€ìˆ˜: {count}ê°œ"))
        for dep_var, var_data in data.items():
            group_count = len(var_data['groups'])
            has_result = 'test_result' in var_data and var_data['test_result'] is not None
            self.root.after(0, lambda var=dep_var, gc=group_count, hr=has_result:
                           self.log(f"      - {var}: {gc}ê°œ ê·¸ë£¹, ê²°ê³¼={'ìˆìŒ' if hr else 'ì—†ìŒ'}"))

        return data

    def extract_ttest_result(self, df: pd.DataFrame, results_start: int, dep_var: str) -> dict:
        """Tê²€ì • ê²°ê³¼ ì¶”ì¶œ"""
        try:
            for i in range(results_start, min(results_start + 30, len(df))):
                if dep_var in str(df.iloc[i, 0]):
                    # ë“±ë¶„ì‚° ê²€ì • í™•ì¸ í›„ ì˜¬ë°”ë¥¸ tê°’ ì„ íƒ
                    for j in range(i, min(i + 3, len(df))):
                        if 'ê°€ì •í•¨' in str(df.iloc[j, 1]) or 'ê°€ì •í•˜ì§€ì•ŠìŒ' in str(df.iloc[j, 1]):
                            t_val, p_val = self.extract_t_and_p_values(df, j)
                            if t_val is not None and p_val is not None:
                                return {'t': t_val, 'p': p_val}
            return None
        except:
            return None

    def extract_anova_result(self, df: pd.DataFrame, results_start: int, dep_var: str) -> dict:
        """ANOVA ê²°ê³¼ ì¶”ì¶œ"""
        try:
            for i in range(results_start, min(results_start + 50, len(df))):
                row_content = " ".join([str(df.iloc[i, col]).strip() for col in range(min(len(df.columns), 10))])

                # ì§‘ë‹¨-ê°„ í–‰ì—ì„œ Fê°’ê³¼ pê°’ ì¶”ì¶œ
                if 'ì§‘ë‹¨-ê°„' in row_content or 'Between Groups' in row_content:
                    f_val, p_val = self.extract_f_and_p_values_enhanced(df, i)
                    if f_val is not None and p_val is not None:
                        return {'f': f_val, 'p': p_val}
            return None
        except:
            return None

    def extract_t_and_p_values(self, df: pd.DataFrame, row: int) -> tuple:
        """Tê°’ê³¼ pê°’ ì¶”ì¶œ"""
        try:
            t_val = None
            p_val = None

            for col in range(2, min(len(df.columns), 10)):
                cell_val = str(df.iloc[row, col]).strip()
                if cell_val and cell_val != '':
                    try:
                        num_val = float(cell_val)
                        if 0 <= num_val <= 1 and p_val is None:  # pê°’
                            p_val = num_val
                        elif abs(num_val) >= 0.001 and t_val is None:  # tê°’
                            t_val = num_val
                    except ValueError:
                        continue

            return t_val, p_val
        except:
            return None, None

    def analyze_difference_test_structure(self, df: pd.DataFrame, stats_tables: list, results_tables: list) -> dict:
        """ì°¨ì´ê²€ì • êµ¬ì¡° ë¶„ì„ìœ¼ë¡œ ë…ë¦½ë³€ìˆ˜ë³„ í…Œì´ë¸” ê·¸ë£¹í™”"""
        indep_var_groups = {}

        # ğŸ¯ ë°©ë²• 1: SPSS ëª…ë ¹ì–´ì—ì„œ ë…ë¦½ë³€ìˆ˜ ì§ì ‘ ì¶”ì¶œ
        command_based_groups = self.group_by_spss_commands(df, stats_tables, results_tables)
        if command_based_groups:
            self.root.after(0, lambda: self.log("  âœ… SPSS ëª…ë ¹ì–´ ê¸°ë°˜ ê·¸ë£¹í™” ì„±ê³µ"))
            return command_based_groups

        # ğŸ¯ ë°©ë²• 2: ì§‘ë‹¨ êµ¬ì¡° ë¶„ì„ìœ¼ë¡œ ë…ë¦½ë³€ìˆ˜ ì¶”ì •
        structure_based_groups = self.group_by_structure_analysis(df, stats_tables, results_tables)
        if structure_based_groups:
            self.root.after(0, lambda: self.log("  âœ… êµ¬ì¡° ë¶„ì„ ê¸°ë°˜ ê·¸ë£¹í™” ì„±ê³µ"))
            return structure_based_groups

        # ğŸ¯ ë°©ë²• 3: ìˆœì„œ ê¸°ë°˜ ê¸°ë³¸ ë§¤í•‘ (ìµœí›„ ìˆ˜ë‹¨)
        self.root.after(0, lambda: self.log("  âš ï¸ ê¸°ë³¸ ìˆœì„œ ë§¤í•‘ ì‚¬ìš©"))
        return self.group_by_order_mapping(stats_tables, results_tables)

    def group_by_spss_commands(self, df: pd.DataFrame, stats_tables: list, results_tables: list) -> dict:
        """SPSS ëª…ë ¹ì–´ ë¶„ì„ìœ¼ë¡œ ë…ë¦½ë³€ìˆ˜ë³„ ê·¸ë£¹í™”"""
        try:
            groups = {}

            # ê° í…Œì´ë¸” ì£¼ë³€ì—ì„œ SPSS ëª…ë ¹ì–´ ì°¾ê¸°
            for stats_table in stats_tables:
                indep_var = self.extract_from_spss_command(df, stats_table['row'])
                if not indep_var:
                    continue

                # í•´ë‹¹ ë…ë¦½ë³€ìˆ˜ì˜ ê²°ê³¼ í…Œì´ë¸” ì°¾ê¸°
                matching_results = []
                for result_table in results_tables:
                    if result_table['type'] == stats_table['type']:
                        # ê°™ì€ ë…ë¦½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸
                        result_indep_var = self.extract_from_spss_command(df, result_table['row'])
                        if result_indep_var == indep_var or not result_indep_var:
                            matching_results.append(result_table)

                if indep_var not in groups:
                    groups[indep_var] = {'stats': [], 'results': []}

                groups[indep_var]['stats'].append(stats_table)
                groups[indep_var]['results'].extend(matching_results)

            return groups if groups else None

        except Exception:
            return None

    def group_by_structure_analysis(self, df: pd.DataFrame, stats_tables: list, results_tables: list) -> dict:
        """ì§‘ë‹¨ êµ¬ì¡° ë¶„ì„ìœ¼ë¡œ ë…ë¦½ë³€ìˆ˜ë³„ ê·¸ë£¹í™”"""
        try:
            groups = {}

            # ê° í†µê³„ í…Œì´ë¸”ì—ì„œ ì§‘ë‹¨ êµ¬ì¡° ë¶„ì„
            for stats_table in stats_tables:
                # ì´ í…Œì´ë¸”ì˜ ì§‘ë‹¨ êµ¬ì¡° ë¶„ì„
                group_structure = self.analyze_table_group_structure(df, stats_table['row'])

                if not group_structure or not group_structure['indep_var']:
                    continue

                indep_var = group_structure['indep_var']
                groups_list = group_structure['groups']

                # ê°™ì€ ì§‘ë‹¨ êµ¬ì¡°ë¥¼ ê°€ì§„ ê²°ê³¼ í…Œì´ë¸” ì°¾ê¸°
                matching_results = []
                for result_table in results_tables:
                    if result_table['type'] == stats_table['type']:
                        # ê²°ê³¼ í…Œì´ë¸”ì´ ê°™ì€ ë…ë¦½ë³€ìˆ˜ë¥¼ ì°¸ì¡°í•˜ëŠ”ì§€ í™•ì¸
                        result_structure = self.analyze_table_group_structure(df, result_table['row'])
                        if (result_structure and
                            result_structure['indep_var'] == indep_var and
                            len(set(result_structure['groups']) & set(groups_list)) >= 2):
                            matching_results.append(result_table)

                if indep_var not in groups:
                    groups[indep_var] = {'stats': [], 'results': []}

                groups[indep_var]['stats'].append(stats_table)
                groups[indep_var]['results'].extend(matching_results)

            return groups if groups else None

        except Exception:
            return None

    def group_by_order_mapping(self, stats_tables: list, results_tables: list) -> dict:
        """ìˆœì„œ ê¸°ë°˜ ê¸°ë³¸ ë§¤í•‘ (ìµœí›„ ìˆ˜ë‹¨)"""
        groups = {}

        # Tê²€ì • ì²˜ë¦¬
        t_stats = [t for t in stats_tables if t['type'] == 't-test']
        t_results = [r for r in results_tables if r['type'] == 't-test']

        if t_stats and t_results:
            # ğŸ¯ Tê²€ì • ë…ë¦½ë³€ìˆ˜ë„ ë™ì  ì¶”ì¶œ (ì„±ë³„ í•˜ë“œì½”ë”© ì œê±°)
            t_indep_var = self.extract_from_spss_command(df, t_stats[0]['row'])
            if not t_indep_var:
                t_indep_var = self.extract_from_table_header(df, t_stats[0]['row'])
            if not t_indep_var:
                t_indep_var = self.extract_from_group_structure(df, t_stats[0]['row'])

            # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            final_var = t_indep_var if t_indep_var else 'Tê²€ì •ë³€ìˆ˜'

            groups[final_var] = {
                'stats': t_stats[:1],
                'results': t_results[:1]
            }

        # ANOVA ì²˜ë¦¬ - ìˆœì„œëŒ€ë¡œ ë§¤í•‘
        anova_stats = [t for t in stats_tables if t['type'] == 'anova']
        anova_results = [r for r in results_tables if r['type'] == 'anova']

        # ğŸ¯ ë™ì  ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ (í•˜ë“œì½”ë”© ì œê±°)
        for i, (stats, results) in enumerate(zip(anova_stats, anova_results)):
            # ì‹¤ì œ ë°ì´í„°ì—ì„œ ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ ì‹œë„
            extracted_var = self.extract_from_spss_command(df, stats['row'])
            if not extracted_var:
                extracted_var = self.extract_from_table_header(df, stats['row'])
            if not extracted_var:
                extracted_var = self.extract_from_group_structure(df, stats['row'])

            # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œì—ë§Œ ìˆœë²ˆ ê¸°ë°˜ ì´ë¦„ ìƒì„±
            var_name = extracted_var if extracted_var else f'ë…ë¦½ë³€ìˆ˜{i+1}'

            groups[var_name] = {
                'stats': [stats],
                'results': [results]
            }

        return groups

    def analyze_table_group_structure(self, df: pd.DataFrame, table_row: int) -> dict:
        """í…Œì´ë¸”ì˜ ì§‘ë‹¨ êµ¬ì¡° ë¶„ì„"""
        try:
            result = {'indep_var': None, 'groups': [], 'dep_vars': []}

            # í…Œì´ë¸” ë°ì´í„° ì˜ì—­ì—ì„œ êµ¬ì¡° ë¶„ì„
            search_range = range(table_row, min(table_row + 100, len(df)))
            current_indep_var = None
            groups_found = []

            for i in search_range:
                if len(df.columns) > 1:
                    col0 = str(df.iloc[i, 0]).strip()
                    col1 = str(df.iloc[i, 1]).strip()

                    # í•œêµ­ì–´ ë³€ìˆ˜ëª… ë°œê²¬
                    if self.is_korean_variable_name(col0):
                        if self.is_group_name(col1):
                            # ì´ê²ƒì€ ë…ë¦½ë³€ìˆ˜ì¼ ê°€ëŠ¥ì„±
                            if not current_indep_var:
                                current_indep_var = col0
                            groups_found.append(col1)
                        else:
                            # ì´ê²ƒì€ ì¢…ì†ë³€ìˆ˜ì¼ ê°€ëŠ¥ì„±
                            result['dep_vars'].append(col0)

            # ê°€ì¥ ë§ì€ ê·¸ë£¹ì„ ê°€ì§„ ë³€ìˆ˜ë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ íŒë‹¨
            if current_indep_var and len(groups_found) >= 2:
                result['indep_var'] = current_indep_var
                result['groups'] = list(set(groups_found))

            return result

        except Exception:
            return {'indep_var': None, 'groups': [], 'dep_vars': []}

    def extract_analyses_by_independent_variable(self, df: pd.DataFrame, indep_var: str, tables: dict) -> None:
        """ë…ë¦½ë³€ìˆ˜ë³„ë¡œ ëª¨ë“  ì¢…ì†ë³€ìˆ˜ì— ëŒ€í•œ ë¶„ì„ ì¶”ì¶œ"""
        try:
            stats_tables = tables['stats']
            results_tables = tables['results']

            if not stats_tables:
                return

            # ì²« ë²ˆì§¸ í†µê³„ í…Œì´ë¸”ì„ ê¸°ì¤€ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ íƒ€ì… ê²°ì •
            test_type = stats_tables[0]['type']

            self.root.after(0, lambda var=indep_var, test=test_type:
                           self.log(f"  ğŸ”¬ {test.upper()} ë¶„ì„ ì‹œì‘: {var}"))

            if test_type == 't-test':
                self.extract_ttest_by_indep_var(df, indep_var, stats_tables, results_tables)
            else:
                self.extract_anova_by_indep_var(df, indep_var, stats_tables, results_tables)

        except Exception as e:
            self.root.after(0, lambda e=e: self.log(f"  âŒ ë¶„ì„ ì¶”ì¶œ ì˜¤ë¥˜: {e}", 'error'))

    def extract_ttest_by_indep_var(self, df: pd.DataFrame, indep_var: str, stats_tables: list, results_tables: list) -> None:
        """ë…ë¦½ë³€ìˆ˜ë³„ Tê²€ì • ë¶„ì„ ì¶”ì¶œ"""
        # ê¸°ì¡´ extract_ttest_analysis ë¡œì§ì„ ë…ë¦½ë³€ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •
        if not stats_tables or not results_tables:
            return

        stats_row = stats_tables[0]['row']
        results_row = results_tables[0]['row']

        # Tê²€ì • ë¶„ì„ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ í™œìš©)
        pair = {
            'indep_var': indep_var,
            'stats_table': stats_tables[0],
            'results_table': results_tables[0]
        }
        self.extract_ttest_analysis(df, pair)

    def extract_anova_by_indep_var(self, df: pd.DataFrame, indep_var: str, stats_tables: list, results_tables: list) -> None:
        """ë…ë¦½ë³€ìˆ˜ë³„ ANOVA ë¶„ì„ ì¶”ì¶œ"""
        # ëª¨ë“  í†µê³„ í…Œì´ë¸”ì—ì„œ ì¢…ì†ë³€ìˆ˜ ì¶”ì¶œ
        all_dep_vars = {}

        for stats_table in stats_tables:
            # ê° í…Œì´ë¸”ì—ì„œ ì¢…ì†ë³€ìˆ˜ì™€ ê·¸ë£¹ ë°ì´í„° ì¶”ì¶œ
            table_data = self.extract_dependent_variables_from_table(df, stats_table['row'], indep_var)
            all_dep_vars.update(table_data)

        # ëª¨ë“  ê²°ê³¼ í…Œì´ë¸”ì—ì„œ ê²€ì • ê²°ê³¼ ì¶”ì¶œ
        all_test_results = {}

        for results_table in results_tables:
            # ê° í…Œì´ë¸”ì—ì„œ Fê°’ê³¼ pê°’ ì¶”ì¶œ
            table_results = self.extract_test_results_from_table(df, results_table['row'], list(all_dep_vars.keys()))
            all_test_results.update(table_results)

        # ì¢…ì†ë³€ìˆ˜ë³„ë¡œ ë¶„ì„ ê²°ê³¼ ì €ì¥
        success_count = 0
        for dep_var in all_dep_vars:
            if dep_var in all_test_results:
                self.all_analyses.append({
                    'indep_var': indep_var,
                    'dep_var': dep_var,
                    'groups': all_dep_vars[dep_var],
                    'statistic': all_test_results[dep_var]['f'],
                    'p_value': all_test_results[dep_var]['p'],
                    'test_type': 'anova'
                })
                self.root.after(0, lambda var=dep_var: self.log(f"    âœ… ì €ì¥: {var}"))
                success_count += 1
            else:
                self.root.after(0, lambda var=dep_var: self.log(f"    âŒ ê²°ê³¼ ì—†ìŒ: {var}", 'warning'))

        self.root.after(0, lambda count=success_count, total=len(all_dep_vars):
                       self.log(f"  ğŸ“Š {indep_var} ë¶„ì„ ì™„ë£Œ: {count}/{total}ê°œ ì„±ê³µ"))

    def extract_dependent_variables_from_table(self, df: pd.DataFrame, table_row: int, indep_var: str) -> dict:
        """í…Œì´ë¸”ì—ì„œ ì¢…ì†ë³€ìˆ˜ë³„ ê·¸ë£¹ ë°ì´í„° ì¶”ì¶œ - ì™„ì „ ê°œì„  ë²„ì „"""
        dep_vars_data = {}

        search_range = range(table_row, min(table_row + 100, len(df)))
        current_dep_var = None

        for i in search_range:
            if len(df.columns) < 2:
                continue

            var_name = str(df.iloc[i, 0]).strip()
            group_name = str(df.iloc[i, 1]).strip()

            # ğŸ¯ ë” ìœ ì—°í•œ ì¢…ì†ë³€ìˆ˜ ì¸ì‹
            if self.is_potential_dependent_variable(var_name):
                current_dep_var = var_name
                if current_dep_var not in dep_vars_data:
                    dep_vars_data[current_dep_var] = []

                # ê°™ì€ í–‰ì— ê·¸ë£¹ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìˆ˜ì§‘
                if self.is_potential_group_name(group_name):
                    group_data = self.extract_group_statistics(df, i)
                    if group_data:
                        dep_vars_data[current_dep_var].append(group_data)

            # ì¢…ì†ë³€ìˆ˜ ë‹¤ìŒ í–‰ë“¤ì—ì„œ ê·¸ë£¹ ë°ì´í„° ìˆ˜ì§‘
            elif current_dep_var and self.is_potential_group_name(var_name):
                group_data = self.extract_group_statistics_from_row(df, i, var_name)
                if group_data:
                    dep_vars_data[current_dep_var].append(group_data)

            # ë‹¤ë¥¸ ì¢…ì†ë³€ìˆ˜ê°€ ì‹œì‘ë˜ê±°ë‚˜ í…Œì´ë¸”ì´ ëë‚˜ë©´ í˜„ì¬ ë³€ìˆ˜ ë¦¬ì…‹
            elif any(keyword in var_name for keyword in ['ANOVA', 'ë¶„ì‚°ë¶„ì„', 'ì§‘ë‹¨-ê°„', 'Between']):
                current_dep_var = None

        # ğŸ¯ ë™ì  ìµœì†Œ ê·¸ë£¹ ì¡°ê±´ (í•˜ë“œì½”ë”© ì œê±°)
        min_groups = self.get_minimum_groups_for_test('anova')  # ANOVA ê¸°ë³¸ê°’
        valid_vars = {}
        for var_name, groups in dep_vars_data.items():
            if len(groups) >= min_groups:
                valid_vars[var_name] = groups
                # ì‹¤ì œ ê·¸ë£¹ëª…ë“¤ì„ ë¡œê·¸ì— í‘œì‹œ
                group_names = [g['group'] for g in groups]
                self.root.after(0, lambda v=var_name, g_names=group_names:
                               self.log(f"    ğŸ“‹ ì¢…ì†ë³€ìˆ˜ ë°œê²¬: {v}"))
                self.root.after(0, lambda g_names=group_names:
                               self.log(f"      â”” ê·¸ë£¹ë“¤: {', '.join(g_names)}"))

        return valid_vars

    def is_potential_dependent_variable(self, var_name: str) -> bool:
        """ì¢…ì†ë³€ìˆ˜ ì •í™• íŒë‹¨ - ê·¸ë£¹ëª…ê³¼ ì™„ì „ êµ¬ë¶„"""
        if not var_name or len(var_name) < 5:  # ì¢…ì†ë³€ìˆ˜ëŠ” ë³´í†µ 5ê¸€ì ì´ìƒ
            return False

        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        try:
            float(var_name)
            return False
        except ValueError:
            pass

        # ğŸš¨ ì ˆëŒ€ ì¢…ì†ë³€ìˆ˜ê°€ ì•„ë‹Œ ê²ƒë“¤ (ê·¸ë£¹ëª…ë“¤)
        definitely_not_dependent = [
            # ì„±ë³„ ê·¸ë£¹
            'ë‚¨ì', 'ì—¬ì', 'ë‚¨ì„±', 'ì—¬ì„±', 'ë‚¨', 'ì—¬',
            # ì—°ë ¹ ê·¸ë£¹
            '30ì„¸', '35ì„¸', '40ì„¸', '20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€', 'ë¯¸ë§Œ', 'ì´ìƒ',
            # ê²½ë ¥ ê·¸ë£¹
            '1ë…„', '2ë…„', '3ë…„', '5ë…„', '10ë…„', 'ì‹ ì…', 'ê²½í—˜ì', 'ë² í…Œë‘',
            # í•™ë ¥ ê·¸ë£¹
            'í•™ì‚¬', 'ì„ì‚¬', 'ë°•ì‚¬', 'ì „ë¬¸ëŒ€', 'ëŒ€í•™ì›', 'ì¡¸ì—…', 'ê³¼ì •',
            # ê¸°ê´€ ê·¸ë£¹
            'ìœ ì¹˜ì›', 'ì–´ë¦°ì´ì§‘', 'êµ­ê³µë¦½', 'ì‚¬ë¦½', 'ë¯¼ê°„', 'ë²•ì¸', 'ê°€ì •',
            # ë‹´ë‹¹ì—°ë ¹ ê·¸ë£¹
            'ë§Œ3ì„¸', 'ë§Œ4ì„¸', 'ë§Œ5ì„¸', 'í˜¼í•©ì—°ë ¹', 'ì˜ì•„', 'ìœ ì•„',
            # êµì‚¬ìˆ˜ ê·¸ë£¹
            '1ëª…', '2ëª…', '3ëª…', '4ëª…', '5ëª…',
            # ë§Œì¡±ë„ ê·¸ë£¹
            'ë§¤ìš°ë‚®ìŒ', 'ë‚®ìŒ', 'ë³´í†µ', 'ë†’ìŒ', 'ë§¤ìš°ë†’ìŒ',
            'ë§¤ìš°ë¶ˆë§Œ', 'ë¶ˆë§Œ', 'ë§Œì¡±', 'ë§¤ìš°ë§Œì¡±',
            # ì°¸ì—¬ ê·¸ë£¹
            'ìˆìŒ', 'ì—†ìŒ', 'ì˜ˆ', 'ì•„ë‹ˆì˜¤', 'ì°¸ì—¬', 'ë¶ˆì°¸',
            # í†µê³„ í‚¤ì›Œë“œ
            'ì§‘ë‹¨-ê°„', 'ì§‘ë‹¨-ë‚´', 'Between', 'Within', 'Groups',
            'ììœ ë„', 'ì œê³±í•©', 'í‰ê· ì œê³±', 'F', 'df', 'SS', 'MS'
        ]

        # ê·¸ë£¹ëª…ì´ë©´ ì¢…ì†ë³€ìˆ˜ê°€ ì•„ë‹˜
        if any(keyword in var_name for keyword in definitely_not_dependent):
            return False

        # ğŸ¯ ì¢…ì†ë³€ìˆ˜ í™•ì‹¤í•œ íŒ¨í„´ë“¤
        definite_dependent_patterns = [
            'ì „ì²´í‰ê· ', 'ì „ì²´í•©ê³„', 'ì „ì²´ì ìˆ˜', 'ì´í‰ê· ', 'ì´í•©ê³„', 'ì´ì ìˆ˜',
            'ì—­ëŸ‰ì „ì²´', 'ì‹ ë…ì „ì²´', 'ì„±ê³¼ì „ì²´', 'ë§Œì¡±ì „ì²´', 'ìŠ¤íŠ¸ë ˆìŠ¤ì „ì²´',
            'í‰ê· ì ìˆ˜', 'í•©ê³„ì ìˆ˜', 'ì¢…í•©ì ìˆ˜'
        ]

        # í™•ì‹¤í•œ ì¢…ì†ë³€ìˆ˜ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì¢…ì†ë³€ìˆ˜
        if any(pattern in var_name for pattern in definite_dependent_patterns):
            return True

        # ğŸ¯ ì¢…ì†ë³€ìˆ˜ ì¼ë°˜ íŒ¨í„´ë“¤ (ë” ì—„ê²©í•œ ì¡°ê±´)
        dependent_patterns = ['ì—­ëŸ‰', 'ì‹ ë…', 'ì„±ê³¼', 'ë§Œì¡±', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'í”¼ë¡œ', 'ë²ˆì•„ì›ƒ']

        if any(pattern in var_name for pattern in dependent_patterns):
            # ì¶”ê°€ ì¡°ê±´: "ì „ì²´", "í‰ê· ", "í•©ê³„" ì¤‘ í•˜ë‚˜ëŠ” í¬í•¨ë˜ì–´ì•¼ í•¨
            if any(suffix in var_name for suffix in ['ì „ì²´', 'í‰ê· ', 'í•©ê³„', 'ì ìˆ˜']):
                return True

        return False

    def is_potential_group_name(self, group_name: str) -> bool:
        """ì‹¤ì œ ê·¸ë£¹ëª…ì¸ì§€ íŒë‹¨ - ëª¨ë“  ì‹¤ì œ ê·¸ë£¹ ë³´ì¥"""
        if not group_name or len(group_name) < 1:
            return False

        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        try:
            float(group_name)
            return False
        except ValueError:
            pass

        # ğŸš¨ ANOVA/Tê²€ì • ì „ìš© í‚¤ì›Œë“œ ì œì™¸ (ì‹¤ì œ ê·¸ë£¹ì´ ì•„ë‹˜)
        statistical_keywords = [
            'ì§‘ë‹¨-ê°„', 'ì§‘ë‹¨-ë‚´', 'Between Groups', 'Within Groups',
            'ììœ ë„', 'ì œê³±í•©', 'í‰ê· ì œê³±', 'F', 'df', 'SS', 'MS',
            'ê²€ì •í†µê³„ëŸ‰', 'ìœ ì˜í™•ë¥ ', 'Sig', 'Significance',
            'ë“±ë¶„ì‚° ê°€ì •í•¨', 'ë“±ë¶„ì‚° ê°€ì •í•˜ì§€ì•ŠìŒ', 'Equal variances',
            'ì—íƒ€ ì œê³±', 'ì—¡ì‹¤ëŸ° ì œê³±', 'Eta Squared'
        ]

        # í†µê³„ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš° ì œì™¸
        if any(keyword in group_name for keyword in statistical_keywords):
            return False

        # ğŸ¯ ì‹¤ì œ ê·¸ë£¹ëª… íŒ¨í„´ë“¤ (í¬í•¨í•´ì•¼ í•  ê²ƒë“¤)
        real_group_patterns = [
            # ì„±ë³„
            'ë‚¨ì', 'ì—¬ì', 'ë‚¨ì„±', 'ì—¬ì„±', 'ë‚¨', 'ì—¬',
            # ì—°ë ¹
            'ì„¸', 'ëŒ€', 'ë¯¸ë§Œ', 'ì´ìƒ', 'ì´í•˜', 'ì´ˆê³¼', '30ì„¸', '35ì„¸', '40ì„¸',
            # ê²½ë ¥
            'ë…„', 'ê°œì›”', 'ì‹ ì…', 'ê²½í—˜ì', 'ë² í…Œë‘', '3ë…„', '5ë…„', '10ë…„',
            # í•™ë ¥
            'ì¡¸ì—…', 'ê³¼ì •', 'í•™ì‚¬', 'ì„ì‚¬', 'ë°•ì‚¬', 'ì „ë¬¸ëŒ€', 'ëŒ€í•™ì›',
            # ê¸°ê´€
            'ìœ ì¹˜ì›', 'ì–´ë¦°ì´ì§‘', 'êµ­ê³µë¦½', 'ì‚¬ë¦½', 'ë¯¼ê°„', 'ë²•ì¸', 'ê°€ì •',
            # ë‹´ë‹¹ì—°ë ¹
            'ë§Œ3ì„¸', 'ë§Œ4ì„¸', 'ë§Œ5ì„¸', 'í˜¼í•©ì—°ë ¹', 'ì˜ì•„', 'ìœ ì•„',
            # êµì‚¬ìˆ˜
            '1ëª…', '2ëª…', '3ëª…', '4ëª…', 'ëª…',
            # ë§Œì¡±ë„/íƒœë„
            'ë§¤ìš°ë¶ˆë§Œ', 'ë¶ˆë§Œ', 'ë³´í†µ', 'ë§Œì¡±', 'ë§¤ìš°ë§Œì¡±',
            'ì „í˜€', 'ê±°ì˜', 'ì•½ê°„', 'ìƒë‹¹íˆ', 'ë§¤ìš°',
            # ì°¸ì—¬/ì´ìš©
            'ì°¸ì—¬', 'ë¶ˆì°¸', 'ìˆìŒ', 'ì—†ìŒ', 'ì˜ˆ', 'ì•„ë‹ˆì˜¤',
            # ì§€ì—­
            'ì„œìš¸', 'ë¶€ì‚°', 'ê²½ê¸°', 'ì¶©ë‚¨', 'ì „ë¶', 'ë„ì‹¬', 'ë†ì´Œ'
        ]

        # ì‹¤ì œ ê·¸ë£¹ëª… íŒ¨í„´ì´ ìˆê±°ë‚˜ í•œêµ­ì–´ì´ë©´ì„œ ì ë‹¹í•œ ê¸¸ì´ë©´ ê·¸ë£¹ëª…
        has_group_pattern = any(pattern in group_name for pattern in real_group_patterns)
        has_korean = any('\uac00' <= char <= '\ud7af' for char in group_name)
        reasonable_length = 1 <= len(group_name) <= 30

        # ì‹¤ì œ ê·¸ë£¹ëª…ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ì¡°ê±´
        if has_group_pattern:
            return True
        elif has_korean and reasonable_length:
            # í•œêµ­ì–´ì´ë©´ì„œ í†µê³„ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê·¸ë£¹ëª…ì¼ ê°€ëŠ¥ì„±
            return True
        elif reasonable_length and group_name.replace(' ', '').replace('-', '').isalnum():
            # ì˜ë¬¸+ìˆ«ì ì¡°í•©ìœ¼ë¡œ ì ë‹¹í•œ ê¸¸ì´ë©´ ê·¸ë£¹ëª…ì¼ ê°€ëŠ¥ì„±
            return True

        return False

    def extract_group_statistics(self, df: pd.DataFrame, row: int) -> dict:
        """í–‰ì—ì„œ ì‹¤ì œ ê·¸ë£¹ í†µê³„ ì¶”ì¶œ - í†µê³„ìš©ì–´ ì œì™¸"""
        try:
            group_name = str(df.iloc[row, 1]).strip()

            # ğŸš¨ í†µê³„ ì „ìš© í‚¤ì›Œë“œëŠ” ê·¸ë£¹ëª…ì´ ì•„ë‹˜
            if not self.is_real_group_name(group_name):
                return None

            # ìˆ«ì ì»¬ëŸ¼ë“¤ ì°¾ê¸° (ë” ìŠ¤ë§ˆíŠ¸í•œ ë°©ì‹)
            numbers = []

            # 2ë²ˆì§¸ ì»¬ëŸ¼ë¶€í„° ìˆ«ì ë°ì´í„° ìˆ˜ì§‘
            for col in range(2, min(len(df.columns), 10)):
                cell_val = str(df.iloc[row, col]).strip()
                if cell_val and cell_val != '':
                    try:
                        num_val = float(cell_val)
                        numbers.append(num_val)
                    except ValueError:
                        continue

            # ğŸ¯ ë™ì  ìµœì†Œ ìˆ«ì ì¡°ê±´ (í•˜ë“œì½”ë”© ì œê±°)
            min_numbers = self.get_minimum_numbers_for_statistics()
            if len(numbers) >= min_numbers:
                # ì²« ë²ˆì§¸ëŠ” N (ë³´í†µ ì •ìˆ˜), ë‘ ë²ˆì§¸ëŠ” í‰ê· , ì„¸ ë²ˆì§¸ëŠ” í‘œì¤€í¸ì°¨
                n_val = int(numbers[0]) if numbers[0] == int(numbers[0]) and 1 <= numbers[0] <= 10000 else None
                mean_val = numbers[1] if 0 <= numbers[1] <= 1000 else None
                std_val = numbers[2] if 0 <= numbers[2] <= 100 else None

                if n_val and mean_val is not None and std_val is not None:
                    return {
                        'group': group_name,
                        'n': n_val,
                        'mean': mean_val,
                        'std': std_val
                    }

            return None

        except Exception:
            return None

    def is_real_group_name(self, group_name: str) -> bool:
        """ì‹¤ì œ ê·¸ë£¹ëª…ì¸ì§€ íŒë‹¨ (í†µê³„ìš©ì–´ ì™„ì „ ì œì™¸)"""
        if not group_name or len(group_name) < 1:
            return False

        # ğŸš¨ ì ˆëŒ€ ê·¸ë£¹ëª…ì´ ì•„ë‹Œ í†µê³„ ì „ìš© í‚¤ì›Œë“œë“¤
        never_group_keywords = [
            # ANOVA í†µê³„ í‚¤ì›Œë“œ
            'ì§‘ë‹¨-ê°„', 'ì§‘ë‹¨-ë‚´', 'Between Groups', 'Within Groups', 'ì§‘ë‹¨ê°„', 'ì§‘ë‹¨ë‚´',
            # í†µê³„ëŸ‰
            'ììœ ë„', 'ì œê³±í•©', 'í‰ê· ì œê³±', 'F', 'df', 'SS', 'MS', 't', 'p',
            'ê²€ì •í†µê³„ëŸ‰', 'ìœ ì˜í™•ë¥ ', 'Sig', 'Significance', 'pê°’', 'Fê°’',
            # ë¶„ì‚° ë¶„ì„ ê´€ë ¨
            'ë“±ë¶„ì‚°', 'ê°€ì •í•¨', 'ê°€ì •í•˜ì§€ì•ŠìŒ', 'Equal variances', 'Variances',
            'ì—íƒ€ ì œê³±', 'ì—¡ì‹¤ëŸ° ì œê³±', 'Eta Squared', 'Epsilon Squared',
            # ê¸°íƒ€ í†µê³„
            'í‰ê· ', 'í‘œì¤€í¸ì°¨', 'Mean', 'Std', 'Standard Deviation', 'N',
            'í•©ê³„', 'ì´í•©', 'ì „ì²´', 'Total', 'Sum'
        ]

        # í†µê³„ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ë©´ ê·¸ë£¹ëª…ì´ ì•„ë‹˜
        if any(keyword in group_name for keyword in never_group_keywords):
            return False

        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°ë„ ê·¸ë£¹ëª…ì´ ì•„ë‹˜
        try:
            float(group_name)
            return False
        except ValueError:
            pass

        # ğŸ¯ ì‹¤ì œ ê·¸ë£¹ëª…ì˜ íŠ¹ì§•
        # 1. í•œêµ­ì–´ê°€ í¬í•¨ë˜ì–´ ìˆê±°ë‚˜
        has_korean = any('\uac00' <= char <= '\ud7af' for char in group_name)

        # 2. ì‹¤ì œ ê·¸ë£¹ì„ ë‚˜íƒ€ë‚´ëŠ” íŒ¨í„´ì´ ìˆê±°ë‚˜
        group_patterns = [
            'ë‚¨', 'ì—¬', 'ì„¸', 'ë…„', 'ëª…', 'ê³¼ì •', 'ì¡¸ì—…', 'ìœ ì¹˜ì›', 'ì–´ë¦°ì´ì§‘',
            'ë§Œì¡±', 'ë¶ˆë§Œ', 'ì°¸ì—¬', 'ë¶ˆì°¸', 'ìˆìŒ', 'ì—†ìŒ', 'ì˜ˆ', 'ì•„ë‹ˆì˜¤',
            'ë¯¸ë§Œ', 'ì´ìƒ', 'ì´í•˜', 'ì´ˆê³¼', 'ëŒ€', 'ê¸‰', 'ìˆ˜ì¤€'
        ]
        has_group_pattern = any(pattern in group_name for pattern in group_patterns)

        # 3. ì ë‹¹í•œ ê¸¸ì´ (ë„ˆë¬´ ê¸¸ë©´ ì„¤ëª…ë¬¸ì¼ ê°€ëŠ¥ì„±)
        reasonable_length = 1 <= len(group_name) <= 25

        return (has_korean or has_group_pattern) and reasonable_length

    def extract_group_statistics_from_row(self, df: pd.DataFrame, row: int, group_name: str) -> dict:
        """ê·¸ë£¹ëª…ì´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì— ìˆëŠ” ê²½ìš°ì˜ í†µê³„ ì¶”ì¶œ - ì‹¤ì œ ê·¸ë£¹ë§Œ"""
        try:
            # ğŸš¨ í†µê³„ ì „ìš© í‚¤ì›Œë“œëŠ” ê·¸ë£¹ëª…ì´ ì•„ë‹˜
            if not self.is_real_group_name(group_name):
                return None

            # 1ë²ˆì§¸ ì»¬ëŸ¼ë¶€í„° ìˆ«ì ë°ì´í„° ì°¾ê¸°
            numbers = []

            for col in range(1, min(len(df.columns), 10)):
                cell_val = str(df.iloc[row, col]).strip()
                if cell_val and cell_val != '':
                    try:
                        num_val = float(cell_val)
                        numbers.append(num_val)
                    except ValueError:
                        continue

            # ğŸ¯ ë™ì  ìµœì†Œ ìˆ«ì ì¡°ê±´ (í•˜ë“œì½”ë”© ì œê±°)
            min_numbers = self.get_minimum_numbers_for_statistics()
            if len(numbers) >= min_numbers:
                # ì²« ë²ˆì§¸ëŠ” N (ë³´í†µ ì •ìˆ˜), ë‘ ë²ˆì§¸ëŠ” í‰ê· , ì„¸ ë²ˆì§¸ëŠ” í‘œì¤€í¸ì°¨
                n_val = int(numbers[0]) if numbers[0] == int(numbers[0]) and 1 <= numbers[0] <= 10000 else None
                mean_val = numbers[1] if 0 <= numbers[1] <= 1000 else None
                std_val = numbers[2] if 0 <= numbers[2] <= 100 else None

                if n_val and mean_val is not None and std_val is not None:
                    return {
                        'group': group_name,
                        'n': n_val,
                        'mean': mean_val,
                        'std': std_val
                    }

            return None

        except Exception:
            return None

    def extract_test_results_from_table(self, df: pd.DataFrame, table_row: int, dep_var_names: list) -> dict:
        """í…Œì´ë¸”ì—ì„œ ê²€ì • ê²°ê³¼ ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
        test_results = {}

        if not dep_var_names:
            return test_results

        search_range = range(table_row, min(table_row + 100, len(df)))
        current_dep_var = None

        for i in search_range:
            row_content = " ".join([str(df.iloc[i, col]).strip() for col in range(min(len(df.columns), 10))])

            # ì¢…ì†ë³€ìˆ˜ ì‹œì‘ í™•ì¸
            first_col = str(df.iloc[i, 0]).strip()
            if first_col in dep_var_names:
                current_dep_var = first_col
                continue

            # ANOVA ê²°ê³¼ í–‰ ì°¾ê¸° (ë” í¬ê´„ì )
            if any(keyword in row_content for keyword in [
                'ì§‘ë‹¨-ê°„', 'Between Groups', 'ì§‘ë‹¨ê°„', 'ì²˜ë¦¬', 'Treatment',
                'ëª¨í˜•', 'Model', 'íšŒê·€', 'Regression'
            ]):
                f_val, p_val = self.extract_f_and_p_values_enhanced(df, i)

                if f_val is not None and p_val is not None:
                    # í˜„ì¬ ì¢…ì†ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê°€ì¥ ê°€ê¹Œìš´ ë³€ìˆ˜ ì°¾ê¸°
                    target_var = current_dep_var if current_dep_var else self.find_closest_dependent_variable(df, i, dep_var_names)

                    if target_var:
                        test_results[target_var] = {'f': f_val, 'p': p_val}
                        self.root.after(0, lambda var=target_var, f=f_val, p=p_val:
                                       self.log(f"    ğŸ“Š ANOVA ê²°ê³¼: {var}, F={f:.3f}, p={p:.6f}"))

        # ì¢…ì†ë³€ìˆ˜ê°€ ìˆì§€ë§Œ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°, ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„
        if not test_results and dep_var_names:
            self.root.after(0, lambda: self.log(f"    ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ANOVA ê²°ê³¼ ì¶”ì¶œ ì‹œë„..."))
            test_results = self.extract_anova_results_alternative(df, table_row, dep_var_names)

        return test_results

    def extract_f_and_p_values_enhanced(self, df: pd.DataFrame, row: int) -> tuple:
        """Fê°’ê³¼ pê°’ ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
        try:
            f_val = None
            p_val = None

            # ì—¬ëŸ¬ ì»¬ëŸ¼ì—ì„œ Fê°’ê³¼ pê°’ ì°¾ê¸° (ë” ë„“ì€ ë²”ìœ„)
            for col in range(min(len(df.columns), 12)):
                cell_val = str(df.iloc[row, col]).strip()
                if cell_val and cell_val != '' and cell_val != '0':
                    try:
                        num_val = float(cell_val)

                        # pê°’ ê°™ì•„ ë³´ì´ëŠ” ê²ƒ (0ê³¼ 1 ì‚¬ì´ì˜ ì‘ì€ ê°’)
                        if 0 <= num_val <= 1 and p_val is None:
                            p_val = num_val
                        # Fê°’ ê°™ì•„ ë³´ì´ëŠ” ê²ƒ (1ë³´ë‹¤ í° ê°’)
                        elif num_val >= 0.001 and f_val is None:
                            f_val = num_val

                    except ValueError:
                        continue

            # Fê°’ê³¼ pê°’ì´ ëª¨ë‘ ì°¾ì•„ì§€ë©´ ë°˜í™˜
            if f_val is not None and p_val is not None:
                return f_val, p_val

            # í•œìª½ë§Œ ì°¾ì•„ì§„ ê²½ìš° ë‹¤ìŒ í–‰ë„ í™•ì¸
            if row + 1 < len(df):
                for col in range(min(len(df.columns), 12)):
                    cell_val = str(df.iloc[row + 1, col]).strip()
                    if cell_val and cell_val != '':
                        try:
                            num_val = float(cell_val)
                            if 0 <= num_val <= 1 and p_val is None:
                                p_val = num_val
                            elif num_val >= 0.001 and f_val is None:
                                f_val = num_val
                        except ValueError:
                            continue

            return f_val, p_val

        except Exception:
            return None, None

    def extract_anova_results_alternative(self, df: pd.DataFrame, table_row: int, dep_var_names: list) -> dict:
        """ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ANOVA ê²°ê³¼ ì¶”ì¶œ"""
        test_results = {}

        try:
            # ì „ì²´ í…Œì´ë¸”ì—ì„œ ìˆ«ì íŒ¨í„´ ì°¾ê¸°
            search_range = range(table_row, min(table_row + 100, len(df)))

            for dep_var in dep_var_names:
                # í•´ë‹¹ ì¢…ì†ë³€ìˆ˜ ì£¼ë³€ì—ì„œ Fê°’ê³¼ pê°’ ì°¾ê¸°
                var_found_row = None

                # ì¢…ì†ë³€ìˆ˜ê°€ ì–¸ê¸‰ëœ í–‰ ì°¾ê¸°
                for i in search_range:
                    if dep_var in str(df.iloc[i, 0]):
                        var_found_row = i
                        break

                if var_found_row:
                    # í•´ë‹¹ ë³€ìˆ˜ ì£¼ë³€ 10í–‰ì—ì„œ Fê°’ê³¼ pê°’ ì°¾ê¸°
                    for check_row in range(var_found_row, min(var_found_row + 10, len(df))):
                        f_val, p_val = self.extract_f_and_p_values_enhanced(df, check_row)
                        if f_val is not None and p_val is not None:
                            test_results[dep_var] = {'f': f_val, 'p': p_val}
                            break

            return test_results

        except Exception:
            return {}

    def find_closest_dependent_variable(self, df: pd.DataFrame, row: int, dep_var_names: list) -> str:
        """ê°€ì¥ ê°€ê¹Œìš´ ì¢…ì†ë³€ìˆ˜ ì°¾ê¸°"""
        try:
            # í˜„ì¬ í–‰ ìœ„ìª½ì—ì„œ ì¢…ì†ë³€ìˆ˜ëª… ì°¾ê¸°
            for i in range(row, max(0, row - 30), -1):
                for col in range(min(3, len(df.columns))):
                    cell_val = str(df.iloc[i, col]).strip()
                    if cell_val in dep_var_names:
                        return cell_val

            # ëª» ì°¾ìœ¼ë©´ ì²« ë²ˆì§¸ ì¢…ì†ë³€ìˆ˜ ë°˜í™˜
            return dep_var_names[0] if dep_var_names else None
        except:
            return None

    def determine_indep_var_from_groups(self, df: pd.DataFrame, stats_row: int) -> str:
        """SPSS ì¶œë ¥ êµ¬ì¡° ë¶„ì„ìœ¼ë¡œ ë…ë¦½ë³€ìˆ˜ ì§ì ‘ ì¶”ì¶œ"""
        try:
            # ğŸ¯ ë°©ë²• 1: SPSS ëª…ë ¹ì–´ì—ì„œ ì§ì ‘ ì¶”ì¶œ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
            command_var = self.extract_from_spss_command(df, stats_row)
            if command_var:
                self.root.after(0, lambda v=command_var:
                               self.log(f"    âœ… SPSS ëª…ë ¹ì–´ì—ì„œ ì¶”ì¶œ: {v}"))
                return command_var

            # ğŸ¯ ë°©ë²• 2: í…Œì´ë¸” í—¤ë”ì—ì„œ ì§ì ‘ ì¶”ì¶œ
            header_var = self.extract_from_table_header(df, stats_row)
            if header_var:
                self.root.after(0, lambda v=header_var:
                               self.log(f"    âœ… í…Œì´ë¸” í—¤ë”ì—ì„œ ì¶”ì¶œ: {v}"))
                return header_var

            # ğŸ¯ ë°©ë²• 3: ë³€ìˆ˜ ë¼ë²¨ì—ì„œ ì¶”ì¶œ (ê°€ì¥ ì •í™•)
            label_var = self.extract_from_variable_labels(df, stats_row)
            if label_var:
                self.root.after(0, lambda v=label_var:
                               self.log(f"    âœ… ë³€ìˆ˜ ë¼ë²¨ì—ì„œ ì¶”ì¶œ: {v}"))
                return label_var

            # ğŸ¯ ë°©ë²• 4: ì§‘ë‹¨ êµ¬ì¡° ë¶„ì„ìœ¼ë¡œ ì¶”ì¶œ
            structure_var = self.extract_from_group_structure(df, stats_row)
            if structure_var:
                self.root.after(0, lambda v=structure_var:
                               self.log(f"    âœ… ì§‘ë‹¨ êµ¬ì¡°ì—ì„œ ì¶”ì¶œ: {v}"))
                return structure_var

            # ğŸ¯ ìµœí›„ ë°©ë²•: íŒ¨í„´ ë§¤ì¹­
            self.root.after(0, lambda: self.log("    âš ï¸ ì§ì ‘ ì¶”ì¶œ ì‹¤íŒ¨, íŒ¨í„´ ë¶„ì„..."))
            return self.fallback_pattern_matching(df, stats_row)

        except Exception as e:
            self.root.after(0, lambda e=e: self.log(f"    âŒ ë…ë¦½ë³€ìˆ˜ ì¶”ì • ì˜¤ë¥˜: {e}"))
            return 'ë…ë¦½ë³€ìˆ˜'

    def extract_indep_var_from_title(self, df: pd.DataFrame, stats_row: int) -> str:
        """í…Œì´ë¸” ì œëª©ì´ë‚˜ ëª…ë ¹ì–´ì—ì„œ ë…ë¦½ë³€ìˆ˜ ì¶”ì •"""
        try:
            # í…Œì´ë¸” ì£¼ë³€ì—ì„œ SPSS ëª…ë ¹ì–´ë‚˜ ì œëª© ì°¾ê¸°
            search_range = range(max(0, stats_row - 10), min(stats_row + 10, len(df)))

            for i in search_range:
                for col in range(min(3, len(df.columns))):
                    cell_content = str(df.iloc[i, col]).strip()

                    if not cell_content:
                        continue

                    # SPSS ëª…ë ¹ì–´ì—ì„œ BY ë‹¤ìŒ ë³€ìˆ˜ëª… ì¶”ì¶œ
                    if 'BY ' in cell_content or 'by ' in cell_content:
                        # BY ë‹¤ìŒì˜ ë³€ìˆ˜ëª… ì¶”ì¶œ
                        parts = cell_content.replace('BY ', 'by ').split('by ')
                        if len(parts) > 1:
                            var_part = parts[1].split()[0].strip()
                            var_name = self.map_variable_to_korean(var_part)
                            if var_name:
                                self.root.after(0, lambda v=var_name, cmd=var_part:
                                               self.log(f"    ğŸ¯ ëª…ë ¹ì–´ì—ì„œ ì¶”ì¶œ: {cmd} â†’ {v}"))
                                return var_name

                    # í…Œì´ë¸” ì œëª©ì—ì„œ ë³€ìˆ˜ëª… ì¶”ì¶œ
                    elif any(pattern in cell_content for pattern in ['ë¶„ì‚°ë¶„ì„', 'ANOVA', 'ì¼ì›ë¶„ì‚°ë¶„ì„', 'ONEWAY']):
                        # ê°™ì€ í–‰ì´ë‚˜ ê·¼ì²˜ì—ì„œ ë³€ìˆ˜ëª… ì°¾ê¸°
                        for search_col in range(min(len(df.columns), 10)):
                            nearby_cell = str(df.iloc[i, search_col]).strip()
                            if 'BY' in nearby_cell or 'by' in nearby_cell:
                                parts = nearby_cell.replace('BY ', 'by ').split('by ')
                                if len(parts) > 1:
                                    var_part = parts[1].split()[0].strip()
                                    var_name = self.map_variable_to_korean(var_part)
                                    if var_name:
                                        self.root.after(0, lambda v=var_name:
                                                       self.log(f"    ğŸ¯ ANOVA ì œëª©ì—ì„œ ì¶”ì¶œ: {v}"))
                                        return var_name

            self.root.after(0, lambda: self.log("    âŒ í…Œì´ë¸” ì œëª©ì—ì„œë„ ë…ë¦½ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"))
            return 'ë…ë¦½ë³€ìˆ˜'

        except Exception as e:
            self.root.after(0, lambda e=e: self.log(f"    âŒ ì œëª© ì¶”ì¶œ ì˜¤ë¥˜: {e}"))
            return 'ë…ë¦½ë³€ìˆ˜'

    def map_variable_to_korean(self, var_code: str) -> str:
        """SPSS ë³€ìˆ˜ì½”ë“œë¥¼ í•œêµ­ì–´ ë³€ìˆ˜ëª…ìœ¼ë¡œ ë§¤í•‘ - ì´ˆê°•í™” ë²„ì „"""

        # ğŸ¯ í¬ê´„ì  ë³€ìˆ˜ ë§¤í•‘ ë°ì´í„°ë² ì´ìŠ¤
        comprehensive_mapping = {
            # === ì¸êµ¬í†µê³„í•™ì  ë³€ìˆ˜ ===
            # ì„±ë³„ ê´€ë ¨
            'ì„±ë³„': 'ì„±ë³„', 'gender': 'ì„±ë³„', 'sex': 'ì„±ë³„', 'ë‚¨ë…€': 'ì„±ë³„', 'male_female': 'ì„±ë³„',
            'q_1ì„±ë³„': 'ì„±ë³„', 'q1_ì„±ë³„': 'ì„±ë³„', 'gender_cat': 'ì„±ë³„', 'ì„±': 'ì„±ë³„',

            # ì—°ë ¹ ê´€ë ¨
            'ì—°ë ¹': 'ì—°ë ¹ë²”ì£¼í™”', 'ì—°ë ¹ëŒ€': 'ì—°ë ¹ë²”ì£¼í™”', 'ì—°ë ¹ë²”ì£¼í™”': 'ì—°ë ¹ë²”ì£¼í™”', 'ì—°ë ¹ê·¸ë£¹': 'ì—°ë ¹ë²”ì£¼í™”',
            'age': 'ì—°ë ¹ë²”ì£¼í™”', 'age_group': 'ì—°ë ¹ë²”ì£¼í™”', 'age_cat': 'ì—°ë ¹ë²”ì£¼í™”', 'agegroup': 'ì—°ë ¹ë²”ì£¼í™”',
            'q_2ì—°ë ¹': 'ì—°ë ¹ë²”ì£¼í™”', 'q2_ì—°ë ¹': 'ì—°ë ¹ë²”ì£¼í™”', 'ë‚˜ì´': 'ì—°ë ¹ë²”ì£¼í™”', 'ë‚˜ì´ëŒ€': 'ì—°ë ¹ë²”ì£¼í™”',
            'ì—°ë ¹êµ¬ê°„': 'ì—°ë ¹ë²”ì£¼í™”', 'ì—°ë ¹ë²”ìœ„': 'ì—°ë ¹ë²”ì£¼í™”', 'age_range': 'ì—°ë ¹ë²”ì£¼í™”',

            # === ì§ì—…/êµìœ¡ ê´€ë ¨ ë³€ìˆ˜ ===
            # ê²½ë ¥ ê´€ë ¨
            'ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'ê·¼ë¬´ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'ì´ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'í˜„ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”',
            'ê²½ë ¥ë²”ì£¼í™”': 'ê²½ë ¥ë²”ì£¼í™”', 'ê²½ë ¥ê¸°ê°„': 'ê²½ë ¥ë²”ì£¼í™”', 'ê·¼ë¬´ë…„ìˆ˜': 'ê²½ë ¥ë²”ì£¼í™”', 'ì¬ì§ê¸°ê°„': 'ê²½ë ¥ë²”ì£¼í™”',
            'career': 'ê²½ë ¥ë²”ì£¼í™”', 'experience': 'ê²½ë ¥ë²”ì£¼í™”', 'work_exp': 'ê²½ë ¥ë²”ì£¼í™”', 'tenure': 'ê²½ë ¥ë²”ì£¼í™”',
            'q_3ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'q3_ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'ì—…ë¬´ê²½í—˜': 'ê²½ë ¥ë²”ì£¼í™”', 'ì§ë¬´ê²½í—˜': 'ê²½ë ¥ë²”ì£¼í™”',
            'í˜„ì¬ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'ì´ê·¼ë¬´ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'í˜„ì§ì¥ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”',

            # êµìœ¡ìˆ˜ì¤€/í•™ë ¥ ê´€ë ¨
            'í•™ë ¥': 'ìµœì¢…í•™ë ¥', 'ìµœì¢…í•™ë ¥': 'ìµœì¢…í•™ë ¥', 'êµìœ¡ìˆ˜ì¤€': 'ìµœì¢…í•™ë ¥', 'êµìœ¡ì •ë„': 'ìµœì¢…í•™ë ¥',
            'education': 'ìµœì¢…í•™ë ¥', 'edu_level': 'ìµœì¢…í•™ë ¥', 'degree': 'ìµœì¢…í•™ë ¥', 'education_level': 'ìµœì¢…í•™ë ¥',
            'q_7í•™ë ¥': 'ìµœì¢…í•™ë ¥', 'q7_í•™ë ¥': 'ìµœì¢…í•™ë ¥', 'ì¡¸ì—…': 'ìµœì¢…í•™ë ¥', 'í•™ìœ„': 'ìµœì¢…í•™ë ¥',
            'êµìœ¡ë°°ê²½': 'ìµœì¢…í•™ë ¥', 'ìˆ˜í•™ì •ë„': 'ìµœì¢…í•™ë ¥', 'í•™ì—…ìˆ˜ì¤€': 'ìµœì¢…í•™ë ¥',

            # ì „ê³µ ê´€ë ¨
            'ì „ê³µ': 'ì „ê³µ', 'ì „ê³µë¶„ì•¼': 'ì „ê³µ', 'ì „ê³µì˜ì—­': 'ì „ê³µ', 'ì „ê³µê³¼ëª©': 'ì „ê³µ', 'í•™ê³¼': 'ì „ê³µ',
            'major': 'ì „ê³µ', 'field': 'ì „ê³µ', 'specialty': 'ì „ê³µ', 'department': 'ì „ê³µ',
            'q_8ì „ê³µ': 'ì „ê³µ', 'q8_ì „ê³µ': 'ì „ê³µ', 'ì„¸ë¶€ì „ê³µ': 'ì „ê³µ', 'ì£¼ì „ê³µ': 'ì „ê³µ',

            # === ê¸°ê´€/ì¡°ì§ ê´€ë ¨ ë³€ìˆ˜ ===
            # ê¸°ê´€ìœ í˜• ê´€ë ¨
            'ê¸°ê´€ìœ í˜•': 'ê¸°ê´€ìœ í˜•', 'ê¸°ê´€í˜•íƒœ': 'ê¸°ê´€ìœ í˜•', 'ê¸°ê´€ì¢…ë¥˜': 'ê¸°ê´€ìœ í˜•', 'ì§ì¥ìœ í˜•': 'ê¸°ê´€ìœ í˜•',
            'ì†Œì†ê¸°ê´€': 'ê¸°ê´€ìœ í˜•', 'ê·¼ë¬´ì§€': 'ê¸°ê´€ìœ í˜•', 'ì§ì¥': 'ê¸°ê´€ìœ í˜•', 'íšŒì‚¬ìœ í˜•': 'ê¸°ê´€ìœ í˜•',
            'institution': 'ê¸°ê´€ìœ í˜•', 'organization': 'ê¸°ê´€ìœ í˜•', 'workplace': 'ê¸°ê´€ìœ í˜•', 'company_type': 'ê¸°ê´€ìœ í˜•',
            'q_4ê¸°ê´€ìœ í˜•': 'ê¸°ê´€ìœ í˜•', 'q4_ê¸°ê´€ìœ í˜•': 'ê¸°ê´€ìœ í˜•', 'ê¸°ê´€ì„±ê²©': 'ê¸°ê´€ìœ í˜•', 'ì¡°ì§í˜•íƒœ': 'ê¸°ê´€ìœ í˜•',

            # ë¶€ì„œ/íŒ€ ê´€ë ¨
            'ë¶€ì„œ': 'ë¶€ì„œ', 'íŒ€': 'íŒ€', 'ê³¼': 'ë¶€ì„œ', 'ì‹¤': 'ë¶€ì„œ', 'ì„¼í„°': 'ë¶€ì„œ',
            'department': 'ë¶€ì„œ', 'team': 'íŒ€', 'division': 'ë¶€ì„œ', 'section': 'ë¶€ì„œ',
            'ì†Œì†ë¶€ì„œ': 'ë¶€ì„œ', 'ë‹´ë‹¹ë¶€ì„œ': 'ë¶€ì„œ', 'ê·¼ë¬´ë¶€ì„œ': 'ë¶€ì„œ',

            # === ì§ë¬´/ì—…ë¬´ ê´€ë ¨ ë³€ìˆ˜ ===
            # ì§ê¸‰/ì§ìœ„ ê´€ë ¨
            'ì§ê¸‰': 'ì§ê¸‰', 'ì§ìœ„': 'ì§ê¸‰', 'ì§ì±…': 'ì§ê¸‰', 'ì§€ìœ„': 'ì§ê¸‰', 'ë“±ê¸‰': 'ì§ê¸‰',
            'position': 'ì§ê¸‰', 'rank': 'ì§ê¸‰', 'grade': 'ì§ê¸‰', 'level': 'ì§ê¸‰', 'title': 'ì§ê¸‰',
            'ê´€ë¦¬ìê¸‰': 'ì§ê¸‰', 'ì¼ë°˜ì§': 'ì§ê¸‰', 'ì„ì›': 'ì§ê¸‰', 'íŒ€ì¥': 'ì§ê¸‰', 'ê³¼ì¥': 'ì§ê¸‰',

            # ê·¼ë¬´í˜•íƒœ ê´€ë ¨
            'ê·¼ë¬´í˜•íƒœ': 'ê·¼ë¬´í˜•íƒœ', 'ê³ ìš©í˜•íƒœ': 'ê·¼ë¬´í˜•íƒœ', 'ê·¼ë¬´ìœ í˜•': 'ê·¼ë¬´í˜•íƒœ', 'ì±„ìš©í˜•íƒœ': 'ê·¼ë¬´í˜•íƒœ',
            'work_type': 'ê·¼ë¬´í˜•íƒœ', 'employment': 'ê·¼ë¬´í˜•íƒœ', 'job_type': 'ê·¼ë¬´í˜•íƒœ',
            'ì •ê·œì§': 'ê·¼ë¬´í˜•íƒœ', 'ë¹„ì •ê·œì§': 'ê·¼ë¬´í˜•íƒœ', 'ê³„ì•½ì§': 'ê·¼ë¬´í˜•íƒœ', 'íŒŒíŠ¸íƒ€ì„': 'ê·¼ë¬´í˜•íƒœ',

            # === ìœ ì•„êµìœ¡/ë³´ìœ¡ ì „ë¬¸ ë³€ìˆ˜ ===
            # ë‹´ë‹¹ì—°ë ¹ ê´€ë ¨
            'ë‹´ë‹¹ì—°ë ¹': 'ë‹´ë‹¹ì—°ë ¹', 'ë‹´ë‹¹ë°˜': 'ë‹´ë‹¹ì—°ë ¹', 'ë‹´ë‹¹í•™ê¸‰': 'ë‹´ë‹¹ì—°ë ¹', 'ë§¡ì€ì—°ë ¹': 'ë‹´ë‹¹ì—°ë ¹',
            'ë°˜ì—°ë ¹': 'ë‹´ë‹¹ì—°ë ¹', 'í•™ê¸‰ì—°ë ¹': 'ë‹´ë‹¹ì—°ë ¹', 'í´ë˜ìŠ¤': 'ë‹´ë‹¹ì—°ë ¹',
            'class_age': 'ë‹´ë‹¹ì—°ë ¹', 'classroom': 'ë‹´ë‹¹ì—°ë ¹', 'assigned_age': 'ë‹´ë‹¹ì—°ë ¹',
            'q_5ë‹´ë‹¹ì—°ë ¹': 'ë‹´ë‹¹ì—°ë ¹', 'q5_ë‹´ë‹¹ì—°ë ¹': 'ë‹´ë‹¹ì—°ë ¹',

            # êµì‚¬ìˆ˜/í•™ê¸‰ê·œëª¨ ê´€ë ¨
            'êµì‚¬ìˆ˜': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'í•™ê¸‰êµì‚¬ìˆ˜': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'êµì‚¬ì¸ì›': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”',
            'ë°˜êµì‚¬ìˆ˜': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'ë‹´ì„êµì‚¬ìˆ˜': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'ë³´ì¡°êµì‚¬': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”',
            'teacher_num': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'class_teacher': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'staff_size': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”',
            'q_6êµì‚¬ìˆ˜': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'q6_êµì‚¬ìˆ˜': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”',

            # ì›ì•„ìˆ˜/í•™ê¸‰ê·œëª¨ ê´€ë ¨
            'ì›ì•„ìˆ˜': 'ì›ì•„ìˆ˜', 'í•™ê¸‰ê·œëª¨': 'ì›ì•„ìˆ˜', 'ë°˜ì¸ì›': 'ì›ì•„ìˆ˜', 'ì•„ë™ìˆ˜': 'ì›ì•„ìˆ˜',
            'ìœ ì•„ìˆ˜': 'ì›ì•„ìˆ˜', 'í•™ìƒìˆ˜': 'ì›ì•„ìˆ˜', 'ì •ì›': 'ì›ì•„ìˆ˜', 'í˜„ì›': 'ì›ì•„ìˆ˜',
            'child_num': 'ì›ì•„ìˆ˜', 'class_size': 'ì›ì•„ìˆ˜', 'student_num': 'ì›ì•„ìˆ˜',

            # === ê±´ê°•/ì˜ë£Œ ê´€ë ¨ ë³€ìˆ˜ ===
            # ì˜ë£Œê¸°ê´€ ê´€ë ¨
            'ì˜ë£Œê¸°ê´€': 'ì˜ë£Œê¸°ê´€ìœ í˜•', 'ë³‘ì›ìœ í˜•': 'ì˜ë£Œê¸°ê´€ìœ í˜•', 'ì§„ë£Œê³¼': 'ì§„ë£Œê³¼',
            'ë³‘ì›ê¸‰ìˆ˜': 'ì˜ë£Œê¸°ê´€ìœ í˜•', 'ì˜ë£Œì§„': 'ì˜ë£Œì§„ìœ í˜•', 'ì§ì¢…': 'ì§ì¢…',

            # === ì§€ì—­/ê±°ì£¼ ê´€ë ¨ ë³€ìˆ˜ ===
            # ì§€ì—­ ê´€ë ¨
            'ì§€ì—­': 'ì§€ì—­', 'ê±°ì£¼ì§€': 'ì§€ì—­', 'ì†Œì¬ì§€': 'ì§€ì—­', 'ìœ„ì¹˜': 'ì§€ì—­',
            'ì‹œë„': 'ì§€ì—­', 'ì‹œêµ°êµ¬': 'ì§€ì—­', 'ë™ë„¤': 'ì§€ì—­', 'êµ¬ì—­': 'ì§€ì—­',
            'region': 'ì§€ì—­', 'location': 'ì§€ì—­', 'area': 'ì§€ì—­', 'district': 'ì§€ì—­',

            # === ê²½ì œ/ì†Œë“ ê´€ë ¨ ë³€ìˆ˜ ===
            # ì†Œë“/ê¸‰ì—¬ ê´€ë ¨
            'ì†Œë“': 'ì†Œë“ìˆ˜ì¤€', 'ê¸‰ì—¬': 'ê¸‰ì—¬ìˆ˜ì¤€', 'ì›”ê¸‰': 'ê¸‰ì—¬ìˆ˜ì¤€', 'ì—°ë´‰': 'ê¸‰ì—¬ìˆ˜ì¤€',
            'ì†Œë“ìˆ˜ì¤€': 'ì†Œë“ìˆ˜ì¤€', 'ê¸‰ì—¬ìˆ˜ì¤€': 'ê¸‰ì—¬ìˆ˜ì¤€', 'ì„ê¸ˆ': 'ê¸‰ì—¬ìˆ˜ì¤€', 'ë³´ìˆ˜': 'ê¸‰ì—¬ìˆ˜ì¤€',
            'income': 'ì†Œë“ìˆ˜ì¤€', 'salary': 'ê¸‰ì—¬ìˆ˜ì¤€', 'wage': 'ê¸‰ì—¬ìˆ˜ì¤€', 'pay': 'ê¸‰ì—¬ìˆ˜ì¤€',

            # === ê°€ì¡±/ê°œì¸ ê´€ë ¨ ë³€ìˆ˜ ===
            # ê²°í˜¼/ê°€ì¡± ê´€ë ¨
            'ê²°í˜¼ìƒíƒœ': 'ê²°í˜¼ìƒíƒœ', 'í˜¼ì¸ìƒíƒœ': 'ê²°í˜¼ìƒíƒœ', 'ê²°í˜¼ì—¬ë¶€': 'ê²°í˜¼ìƒíƒœ', 'í˜¼ì¸ì—¬ë¶€': 'ê²°í˜¼ìƒíƒœ',
            'ê°€ì¡±êµ¬ì„±': 'ê°€ì¡±êµ¬ì„±', 'ê°€ì¡±í˜•íƒœ': 'ê°€ì¡±êµ¬ì„±', 'ìë…€ìˆ˜': 'ìë…€ìˆ˜', 'ìë…€ì—¬ë¶€': 'ìë…€ì—¬ë¶€',
            'marital_status': 'ê²°í˜¼ìƒíƒœ', 'family_type': 'ê°€ì¡±êµ¬ì„±', 'children': 'ìë…€ìˆ˜',

            # === íƒœë„/ì˜ê²¬ ê´€ë ¨ ë³€ìˆ˜ ===
            # ë§Œì¡±ë„ ê´€ë ¨
            'ë§Œì¡±ë„': 'ë§Œì¡±ë„', 'ë§Œì¡±ìˆ˜ì¤€': 'ë§Œì¡±ë„', 'ë§Œì¡±ì •ë„': 'ë§Œì¡±ë„',
            'satisfaction': 'ë§Œì¡±ë„', 'satisfaction_level': 'ë§Œì¡±ë„',
            'ì§ë¬´ë§Œì¡±': 'ì§ë¬´ë§Œì¡±ë„', 'ìƒí™œë§Œì¡±': 'ìƒí™œë§Œì¡±ë„', 'ì„œë¹„ìŠ¤ë§Œì¡±': 'ì„œë¹„ìŠ¤ë§Œì¡±ë„',

            # === í–‰ë™/ì„±ê³¼ ê´€ë ¨ ë³€ìˆ˜ ===
            # ì„±ê³¼/í‰ê°€ ê´€ë ¨
            'ì„±ê³¼': 'ì„±ê³¼', 'ì‹¤ì ': 'ì„±ê³¼', 'í‰ê°€': 'í‰ê°€ê²°ê³¼', 'ë“±ê¸‰': 'í‰ê°€ë“±ê¸‰',
            'performance': 'ì„±ê³¼', 'achievement': 'ì„±ê³¼', 'evaluation': 'í‰ê°€ê²°ê³¼',

            # === ê¸°íƒ€ íŠ¹ìˆ˜ ë³€ìˆ˜ ===
            # ì‹œê°„ ê´€ë ¨
            'ì‹œê°„': 'ì‹œê°„ëŒ€', 'ê¸°ê°„': 'ê¸°ê°„', 'ì£¼ê¸°': 'ì£¼ê¸°', 'ë¹ˆë„': 'ë¹ˆë„',
            'time': 'ì‹œê°„ëŒ€', 'period': 'ê¸°ê°„', 'frequency': 'ë¹ˆë„',

            # ì°¸ì—¬/ì´ìš© ê´€ë ¨
            'ì°¸ì—¬ì—¬ë¶€': 'ì°¸ì—¬ì—¬ë¶€', 'ì´ìš©ì—¬ë¶€': 'ì´ìš©ì—¬ë¶€', 'ê²½í—˜ì—¬ë¶€': 'ê²½í—˜ì—¬ë¶€',
            'ì°¸ì—¬ì •ë„': 'ì°¸ì—¬ì •ë„', 'ì´ìš©ì •ë„': 'ì´ìš©ì •ë„', 'í™œìš©ì •ë„': 'í™œìš©ì •ë„',
            'participation': 'ì°¸ì—¬ì—¬ë¶€', 'usage': 'ì´ìš©ì—¬ë¶€', 'experience': 'ê²½í—˜ì—¬ë¶€',
        }

        # 1. ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
        var_lower = var_code.lower().strip()
        if var_code in comprehensive_mapping:
            return comprehensive_mapping[var_code]
        if var_lower in comprehensive_mapping:
            return comprehensive_mapping[var_lower]

        # 2. ë¶€ë¶„ ì¼ì¹˜ ê²€ì‚¬ (ê¸´ í‚¤ì›Œë“œë¶€í„°)
        sorted_keys = sorted(comprehensive_mapping.keys(), key=len, reverse=True)
        for key in sorted_keys:
            if key in var_code or var_code in key:
                return comprehensive_mapping[key]
            if key.lower() in var_lower or var_lower in key.lower():
                return comprehensive_mapping[key]

        # 3. ê³ ê¸‰ íŒ¨í„´ ê¸°ë°˜ ì¶”ì •
        return self.advanced_pattern_matching(var_code)

    def advanced_pattern_matching(self, var_code: str) -> str:
        """ê³ ê¸‰ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë³€ìˆ˜ ì¶”ì •"""
        var_lower = var_code.lower()

        # ğŸ” íŒ¨í„´ ë¶„ì„ ê·œì¹™ë“¤
        pattern_rules = [
            # ì—°ë ¹ ê´€ë ¨ íŒ¨í„´
            (['ì—°ë ¹', 'ë‚˜ì´', 'ì„¸', 'age', 'old', 'ë…„ìƒ', 'birth'], 'ì—°ë ¹ë²”ì£¼í™”'),
            (['ê²½ë ¥', 'ê·¼ë¬´', 'ì¬ì§', 'ë…„ì°¨', 'career', 'exp', 'work', 'service', 'ë…„'], 'ê²½ë ¥ë²”ì£¼í™”'),
            (['ì„±ë³„', 'ë‚¨ë…€', 'ì„±', 'gender', 'sex', 'male', 'female'], 'ì„±ë³„'),
            (['í•™ë ¥', 'êµìœ¡', 'ì¡¸ì—…', 'í•™ìœ„', 'education', 'degree', 'academic'], 'ìµœì¢…í•™ë ¥'),
            (['ì „ê³µ', 'í•™ê³¼', 'ê³¼ì •', 'major', 'field', 'specialty', 'study'], 'ì „ê³µ'),
            (['ê¸°ê´€', 'íšŒì‚¬', 'ì§ì¥', 'ì¡°ì§', 'institution', 'company', 'organization'], 'ê¸°ê´€ìœ í˜•'),
            (['ì§ê¸‰', 'ì§ìœ„', 'ì§ì±…', 'position', 'rank', 'grade', 'level'], 'ì§ê¸‰'),
            (['ë¶€ì„œ', 'íŒ€', 'ê³¼', 'ì‹¤', 'department', 'team', 'division'], 'ë¶€ì„œ'),
            (['ê·¼ë¬´í˜•íƒœ', 'ê³ ìš©', 'ì±„ìš©', 'employment', 'work_type', 'job'], 'ê·¼ë¬´í˜•íƒœ'),
            (['ì§€ì—­', 'ê±°ì£¼', 'ì†Œì¬', 'ìœ„ì¹˜', 'region', 'location', 'area'], 'ì§€ì—­'),
            (['ì†Œë“', 'ê¸‰ì—¬', 'ì›”ê¸‰', 'ì—°ë´‰', 'income', 'salary', 'wage'], 'ì†Œë“ìˆ˜ì¤€'),
            (['ê²°í˜¼', 'í˜¼ì¸', 'ë°°ìš°ì', 'marriage', 'marital', 'spouse'], 'ê²°í˜¼ìƒíƒœ'),
            (['ìë…€', 'ì•„ì´', 'ì•„ë“¤', 'ë”¸', 'child', 'son', 'daughter'], 'ìë…€ìˆ˜'),
            (['ë§Œì¡±', 'satisfaction', 'satisfy'], 'ë§Œì¡±ë„'),
            (['ì„±ê³¼', 'ì‹¤ì ', 'í‰ê°€', 'performance', 'achievement', 'result'], 'ì„±ê³¼'),
            (['ì°¸ì—¬', 'ì´ìš©', 'í™œìš©', 'ê²½í—˜', 'participation', 'usage', 'experience'], 'ì°¸ì—¬ì—¬ë¶€'),
            (['ì‹œê°„', 'ê¸°ê°„', 'ì£¼ê¸°', 'time', 'period', 'duration'], 'ì‹œê°„ëŒ€'),
            (['ë¹ˆë„', 'íšŸìˆ˜', 'frequency', 'times', 'count'], 'ë¹ˆë„'),

            # ìœ ì•„êµìœ¡ íŠ¹í™” íŒ¨í„´
            (['ë‹´ë‹¹', 'ë§¡ì€', 'ë°˜', 'í•™ê¸‰', 'class', 'assigned'], 'ë‹´ë‹¹ì—°ë ¹'),
            (['êµì‚¬ìˆ˜', 'êµì‚¬ì¸ì›', 'ì„ ìƒë‹˜', 'teacher', 'staff'], 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”'),
            (['ì›ì•„', 'ìœ ì•„', 'ì•„ë™', 'ì•„ì´', 'child', 'student'], 'ì›ì•„ìˆ˜'),
            (['ìœ ì¹˜ì›', 'ì–´ë¦°ì´ì§‘', 'ë³´ìœ¡', 'kindergarten', 'daycare'], 'ê¸°ê´€ìœ í˜•'),

            # ì˜ë£Œ/ê±´ê°• íŠ¹í™” íŒ¨í„´
            (['ë³‘ì›', 'ì˜ë£Œ', 'í´ë¦¬ë‹‰', 'hospital', 'medical', 'clinic'], 'ì˜ë£Œê¸°ê´€ìœ í˜•'),
            (['ì§„ë£Œê³¼', 'ê³¼', 'ì „ë¬¸ì˜', 'department', 'specialty'], 'ì§„ë£Œê³¼'),
            (['ê°„í˜¸ì‚¬', 'ì˜ì‚¬', 'ì˜ë£Œì§„', 'nurse', 'doctor', 'medical_staff'], 'ì§ì¢…'),
        ]

        # íŒ¨í„´ ë§¤ì¹­ ì‹¤í–‰
        for patterns, result in pattern_rules:
            if any(pattern in var_lower for pattern in patterns):
                return result

        # 4. ìˆ«ì íŒ¨í„´ ë¶„ì„
        if var_code.isdigit():
            return None  # ìˆœìˆ˜ ìˆ«ìëŠ” ë…ë¦½ë³€ìˆ˜ê°€ ì•„ë‹˜

        # 5. íŠ¹ìˆ˜ íŒ¨í„´ (q_ìˆ«ì í˜•íƒœ)
        import re
        q_pattern = re.match(r'q_?(\d+)(.+)', var_lower)
        if q_pattern:
            var_name = q_pattern.group(2)
            return self.advanced_pattern_matching(var_name)

        return None

    def extract_from_spss_command(self, df: pd.DataFrame, stats_row: int) -> str:
        """SPSS ëª…ë ¹ì–´ì—ì„œ ì§ì ‘ ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ"""
        try:
            # í…Œì´ë¸” ì£¼ë³€ì—ì„œ SPSS ëª…ë ¹ì–´ ì°¾ê¸°
            search_range = range(max(0, stats_row - 20), min(stats_row + 20, len(df)))

            for i in search_range:
                for col in range(min(len(df.columns), 5)):
                    cell = str(df.iloc[i, col]).strip()

                    # T-TEST ëª…ë ¹ì–´ íŒ¨í„´
                    if 'T-TEST' in cell and 'GROUPS=' in cell:
                        # T-TEST GROUPS=ë³€ìˆ˜ëª…(ê°’1 ê°’2) íŒ¨í„´
                        import re
                        pattern = r'GROUPS?=([^(\s]+)'
                        match = re.search(pattern, cell)
                        if match:
                            var_name = match.group(1).strip()
                            return self.clean_variable_name(var_name)

                    # ONEWAY ëª…ë ¹ì–´ íŒ¨í„´
                    elif 'ONEWAY' in cell and ' BY ' in cell:
                        # ONEWAY ì¢…ì†ë³€ìˆ˜ BY ë…ë¦½ë³€ìˆ˜ íŒ¨í„´
                        parts = cell.split(' BY ')
                        if len(parts) >= 2:
                            var_part = parts[1].split()[0].strip()
                            return self.clean_variable_name(var_part)

                    # ANOVA ëª…ë ¹ì–´ íŒ¨í„´
                    elif 'ANOVA' in cell and ' BY ' in cell:
                        parts = cell.split(' BY ')
                        if len(parts) >= 2:
                            var_part = parts[1].split()[0].strip()
                            return self.clean_variable_name(var_part)

            return None

        except Exception:
            return None

    def extract_from_table_header(self, df: pd.DataFrame, stats_row: int) -> str:
        """í…Œì´ë¸” í—¤ë”ë‚˜ ì œëª©ì—ì„œ ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ"""
        try:
            # í…Œì´ë¸” ì œëª© í–‰ë“¤ í™•ì¸
            title_range = range(max(0, stats_row - 5), stats_row + 1)

            for i in title_range:
                for col in range(min(len(df.columns), 3)):
                    cell = str(df.iloc[i, col]).strip()

                    # ë…ë¦½ë³€ìˆ˜ê°€ ëª…ì‹œëœ ì œëª© íŒ¨í„´
                    if any(keyword in cell for keyword in ['ë¶„ì‚°ë¶„ì„', 'ANOVA', 'ì¼ì›ë¶„ì‚°ë¶„ì„']):
                        # ë‹¤ìŒ í–‰ì´ë‚˜ ê°™ì€ í–‰ì—ì„œ ë³€ìˆ˜ëª… ì°¾ê¸°
                        for check_row in range(i, min(i + 3, len(df))):
                            for check_col in range(min(len(df.columns), 5)):
                                check_cell = str(df.iloc[check_row, check_col]).strip()
                                if self.is_korean_variable_name(check_cell):
                                    return check_cell

                    # Tê²€ì • ì œëª©ì—ì„œ ë³€ìˆ˜ëª… ì°¾ê¸°
                    elif any(keyword in cell for keyword in ['ì§‘ë‹¨í†µê³„', 'Group Statistics']):
                        # ë°”ë¡œ ë‹¤ìŒ ëª‡ í–‰ì—ì„œ ë³€ìˆ˜ëª… ì°¾ê¸°
                        for check_row in range(i + 1, min(i + 5, len(df))):
                            var_col_content = str(df.iloc[check_row, 0]).strip()
                            if self.is_korean_variable_name(var_col_content):
                                # í•´ë‹¹ ë³€ìˆ˜ì˜ ì§‘ë‹¨ì„ ë³´ê³  ë…ë¦½ë³€ìˆ˜ ì¶”ì •
                                return self.infer_indep_var_from_dependent(var_col_content)

            return None

        except Exception:
            return None

    def extract_from_variable_labels(self, df: pd.DataFrame, stats_row: int) -> str:
        """ë³€ìˆ˜ ë¼ë²¨ì´ë‚˜ ì„¤ëª…ì—ì„œ ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ"""
        try:
            # í…Œì´ë¸”ì—ì„œ ë³€ìˆ˜ ë¼ë²¨ ì˜ì—­ ì°¾ê¸°
            search_range = range(stats_row, min(stats_row + 50, len(df)))

            for i in search_range:
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì—ì„œ í•œêµ­ì–´ ë³€ìˆ˜ëª… ì°¾ê¸°
                first_col = str(df.iloc[i, 0]).strip()

                if self.is_korean_variable_name(first_col):
                    # ì´ ë³€ìˆ˜ê°€ ì¢…ì†ë³€ìˆ˜ì¸ì§€ ë…ë¦½ë³€ìˆ˜ì¸ì§€ íŒë‹¨
                    # ê°™ì€ í–‰ì˜ ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì— ê·¸ë£¹ëª…ì´ ìˆìœ¼ë©´ ë…ë¦½ë³€ìˆ˜
                    if len(df.columns) > 1:
                        second_col = str(df.iloc[i, 1]).strip()
                        if self.is_group_name(second_col):
                            return first_col

                    # ë‹¤ìŒ ëª‡ í–‰ì— ê·¸ë£¹ë“¤ì´ ë‚˜ì—´ë˜ì–´ ìˆìœ¼ë©´ ë…ë¦½ë³€ìˆ˜
                    groups_found = 0
                    for j in range(i + 1, min(i + 10, len(df))):
                        if len(df.columns) > 1:
                            potential_group = str(df.iloc[j, 1]).strip()
                            if self.is_group_name(potential_group):
                                groups_found += 1

                    if groups_found >= 2:  # 2ê°œ ì´ìƒ ê·¸ë£¹ì´ ìˆìœ¼ë©´ ë…ë¦½ë³€ìˆ˜
                        return first_col

            return None

        except Exception:
            return None

    def extract_from_group_structure(self, df: pd.DataFrame, stats_row: int) -> str:
        """ì§‘ë‹¨ êµ¬ì¡° ë¶„ì„ìœ¼ë¡œ ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ"""
        try:
            # ì§‘ë‹¨ ë°ì´í„°ê°€ ìˆëŠ” ì˜ì—­ ë¶„ì„
            search_range = range(stats_row, min(stats_row + 100, len(df)))
            group_structures = {}

            for i in search_range:
                if len(df.columns) > 1:
                    var_name = str(df.iloc[i, 0]).strip()
                    group_name = str(df.iloc[i, 1]).strip()

                    # í•œêµ­ì–´ ë³€ìˆ˜ëª…ê³¼ ê·¸ë£¹ëª…ì´ ìˆëŠ” í–‰
                    if (self.is_korean_variable_name(var_name) and
                        self.is_group_name(group_name) and
                        var_name != group_name):

                        if var_name not in group_structures:
                            group_structures[var_name] = []
                        group_structures[var_name].append(group_name)

            # ê°€ì¥ ë§ì€ ê·¸ë£¹ì„ ê°€ì§„ ë³€ìˆ˜ë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ íŒë‹¨
            if group_structures:
                # ê·¸ë£¹ ìˆ˜ê°€ 2ê°œ ì´ìƒì¸ ë³€ìˆ˜ë“¤ë§Œ ê³ ë ¤
                valid_vars = {k: v for k, v in group_structures.items() if len(v) >= 2}
                if valid_vars:
                    # ê·¸ë£¹ ìˆ˜ê°€ ê°€ì¥ ë§ì€ ë³€ìˆ˜ ì„ íƒ (ë” ì„¸ë¶„í™”ëœ ë³€ìˆ˜ê°€ ë…ë¦½ë³€ìˆ˜ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
                    indep_var = max(valid_vars.keys(), key=lambda x: len(valid_vars[x]))
                    self.root.after(0, lambda v=indep_var, groups=valid_vars[indep_var]:
                                   self.log(f"    ğŸ“Š ì§‘ë‹¨ êµ¬ì¡° ë¶„ì„: {v} -> {groups}"))
                    return indep_var

            return None

        except Exception:
            return None

    def clean_variable_name(self, var_name: str) -> str:
        """ë³€ìˆ˜ëª… ì •ë¦¬ ë° í•œêµ­ì–´ ë³€í™˜"""
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        cleaned = var_name.replace('(', '').replace(')', '').replace('[', '').replace(']', '')
        cleaned = cleaned.replace('\n', '').replace('\t', '').strip()

        # SPSS ë³€ìˆ˜ì½”ë“œë¥¼ í•œêµ­ì–´ë¡œ ë³€í™˜
        korean_name = self.convert_spss_code_to_korean(cleaned)
        return korean_name if korean_name else cleaned

    def convert_spss_code_to_korean(self, var_code: str) -> str:
        """SPSS ë³€ìˆ˜ì½”ë“œë¥¼ í•œêµ­ì–´ë¡œ ë³€í™˜ - ê°•í™” ë²„ì „"""
        # í¬ê´„ì  ë³€ìˆ˜ ë§¤í•‘
        variable_mappings = {
            # ê¸°ë³¸ ì¸êµ¬í†µê³„í•™ì  ë³€ìˆ˜
            'q_1ì„±ë³„': 'ì„±ë³„', 'q1ì„±ë³„': 'ì„±ë³„', 'q_2ì„±ë³„': 'ì„±ë³„', 'q2ì„±ë³„': 'ì„±ë³„',
            'gender': 'ì„±ë³„', 'sex': 'ì„±ë³„',

            # ì—°ë ¹ ê´€ë ¨
            'q_2ì—°ë ¹': 'ì—°ë ¹ë²”ì£¼í™”', 'q2ì—°ë ¹': 'ì—°ë ¹ë²”ì£¼í™”', 'q_3ì—°ë ¹': 'ì—°ë ¹ë²”ì£¼í™”',
            'age': 'ì—°ë ¹ë²”ì£¼í™”', 'ì—°ë ¹ë²”ì£¼í™”': 'ì—°ë ¹ë²”ì£¼í™”',

            # ì¢…êµ
            'q_3ì¢…êµ': 'ì¢…êµ', 'q3ì¢…êµ': 'ì¢…êµ', 'religion': 'ì¢…êµ',

            # ê²°í˜¼ìƒíƒœ
            'q_4ê²°í˜¼': 'ê²°í˜¼ìƒíƒœ', 'q4ê²°í˜¼': 'ê²°í˜¼ìƒíƒœ', 'marriage': 'ê²°í˜¼ìƒíƒœ',
            'marital': 'ê²°í˜¼ìƒíƒœ',

            # í•™ë ¥
            'q_5í•™ë ¥': 'ìµœì¢…í•™ë ¥', 'q5í•™ë ¥': 'ìµœì¢…í•™ë ¥', 'q_7í•™ë ¥': 'ìµœì¢…í•™ë ¥',
            'education': 'ìµœì¢…í•™ë ¥', 'degree': 'ìµœì¢…í•™ë ¥',

            # ë¶€ì„œ/ì§ì¥
            'q_6ë¶€ì„œ': 'ê·¼ë¬´ë¶€ì„œ', 'q6ë¶€ì„œ': 'ê·¼ë¬´ë¶€ì„œ', 'department': 'ê·¼ë¬´ë¶€ì„œ',
            'q_7í¬ë§ë¶€ì„œë°°ì¹˜ì—¬ë¶€': 'í¬ë§ë¶€ì„œë°°ì¹˜ì—¬ë¶€',

            # ê²½ë ¥
            'q_3ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'q3ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'ì´ê²½ë ¥ë²”ì£¼í™”': 'ì´ê²½ë ¥ë²”ì£¼í™”',
            'ê²½ë ¥ë²”ì£¼í™”': 'ê²½ë ¥ë²”ì£¼í™”', 'í˜„ê²½ë ¥ë²”ì£¼í™”': 'ê²½ë ¥ë²”ì£¼í™”',
            'career': 'ê²½ë ¥ë²”ì£¼í™”', 'experience': 'ê²½ë ¥ë²”ì£¼í™”',

            # ê¸°ê´€/ì¡°ì§
            'q_4ê¸°ê´€': 'ê¸°ê´€ìœ í˜•', 'q4ê¸°ê´€': 'ê¸°ê´€ìœ í˜•', 'ê¸°ê´€ìœ í˜•': 'ê¸°ê´€ìœ í˜•',
            'institution': 'ê¸°ê´€ìœ í˜•', 'organization': 'ê¸°ê´€ìœ í˜•',

            # ë‹´ë‹¹ì—…ë¬´
            'q_5ë‹´ë‹¹': 'ë‹´ë‹¹ì—°ë ¹', 'q5ë‹´ë‹¹': 'ë‹´ë‹¹ì—°ë ¹', 'ë‹´ë‹¹ì—°ë ¹': 'ë‹´ë‹¹ì—°ë ¹',
            'class': 'ë‹´ë‹¹ì—°ë ¹', 'classroom': 'ë‹´ë‹¹ì—°ë ¹',

            # êµì‚¬ìˆ˜
            'q_6êµì‚¬': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'q6êµì‚¬': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”',
            'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'teacher': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”',

            # ì „ê³µ
            'q_8ì „ê³µ': 'ì „ê³µ', 'q8ì „ê³µ': 'ì „ê³µ', 'ì „ê³µ': 'ì „ê³µ',
            'major': 'ì „ê³µ', 'field': 'ì „ê³µ',

            # ê¸°íƒ€ ì§ì¥/ì—…ë¬´ ê´€ë ¨
            'q_9ë¶€ë‹´': 'ì—…ë¬´ë¶€ë‹´', 'q_10ì´ì§': 'ì´ì§ì˜ë„', 'q_11ë§Œì¡±ë„': 'ì§ë¬´ë§Œì¡±ë„',
            'q_12ê¸‰ì—¬': 'ê¸‰ì—¬ìˆ˜ì¤€', 'q_13ê·¼ë¬´í˜•íƒœ': 'ê·¼ë¬´í˜•íƒœ',

            # ìµœì¢…í•™ë ¥
            'ìµœì¢…í•™ë ¥': 'ìµœì¢…í•™ë ¥'
        }

        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
        if var_code in variable_mappings:
            return variable_mappings[var_code]

        # ë¶€ë¶„ ì¼ì¹˜ ê²€ì‚¬
        for key, value in variable_mappings.items():
            if key in var_code or var_code in key:
                return value

        # íŒ¨í„´ ê¸°ë°˜ ë³€í™˜
        if 'q_' in var_code or 'q' in var_code:
            # q_ìˆ«ìíŒ¨í„´ ë¶„ì„
            import re

            # ì„±ë³„ íŒ¨í„´
            if any(pattern in var_code.lower() for pattern in ['ì„±ë³„', 'gender', 'sex']):
                return 'ì„±ë³„'
            # ì—°ë ¹ íŒ¨í„´
            elif any(pattern in var_code.lower() for pattern in ['ì—°ë ¹', 'age']):
                return 'ì—°ë ¹ë²”ì£¼í™”'
            # ì¢…êµ íŒ¨í„´
            elif any(pattern in var_code.lower() for pattern in ['ì¢…êµ', 'religion']):
                return 'ì¢…êµ'
            # ê²°í˜¼ íŒ¨í„´
            elif any(pattern in var_code.lower() for pattern in ['ê²°í˜¼', 'marriage', 'marital']):
                return 'ê²°í˜¼ìƒíƒœ'
            # í•™ë ¥ íŒ¨í„´
            elif any(pattern in var_code.lower() for pattern in ['í•™ë ¥', 'education', 'degree']):
                return 'ìµœì¢…í•™ë ¥'
            # ë¶€ì„œ íŒ¨í„´
            elif any(pattern in var_code.lower() for pattern in ['ë¶€ì„œ', 'department', 'dept']):
                return 'ê·¼ë¬´ë¶€ì„œ'
            # ê²½ë ¥ íŒ¨í„´
            elif any(pattern in var_code.lower() for pattern in ['ê²½ë ¥', 'career', 'exp']):
                return 'ê²½ë ¥ë²”ì£¼í™”'

        # í•œêµ­ì–´ ë³€ìˆ˜ëª…ì€ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if any('\uac00' <= char <= '\ud7af' for char in var_code):
            return var_code

        return None

    def is_korean_variable_name(self, text: str) -> bool:
        """í•œêµ­ì–´ ë³€ìˆ˜ëª…ì¸ì§€ íŒë‹¨"""
        if not text or len(text) < 2:
            return False

        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        try:
            float(text)
            return False
        except ValueError:
            pass

        # í•œêµ­ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
        has_korean = any('\uac00' <= char <= '\ud7af' for char in text)

        # ì¼ë°˜ì ì¸ ë³€ìˆ˜ëª… íŒ¨í„´ í™•ì¸
        common_var_patterns = [
            'ë²”ì£¼í™”', 'ìœ í˜•', 'í˜•íƒœ', 'ìˆ˜ì¤€', 'ì •ë„', 'ì—¬ë¶€', 'ìƒíƒœ', 'ë“±ê¸‰',
            'ì—°ë ¹', 'ê²½ë ¥', 'í•™ë ¥', 'ì „ê³µ', 'ì„±ë³„', 'ì§€ì—­', 'ì†Œë“', 'ë§Œì¡±',
            'ê¸°ê´€', 'ë‹´ë‹¹', 'êµì‚¬', 'ê·¼ë¬´', 'ì§ê¸‰', 'ë¶€ì„œ'
        ]

        if has_korean or any(pattern in text for pattern in common_var_patterns):
            # ì œì™¸í•  íŒ¨í„´ë“¤
            exclude_patterns = [
                'í‰ê· ', 'í‘œì¤€í¸ì°¨', 'í•©ê³„', 'ì ìˆ˜', 'ì´í•©', 'ì „ì²´',
                'ì§‘ë‹¨í†µê³„', 'ê¸°ìˆ í†µê³„', 'ë¶„ì‚°ë¶„ì„', 'ANOVA', 'T-TEST',
                'ê²€ì •í†µê³„ëŸ‰', 'ìœ ì˜í™•ë¥ ', 'ììœ ë„', 'ì œê³±í•©'
            ]

            if not any(pattern in text for pattern in exclude_patterns):
                return True

        return False

    def is_group_name(self, text: str) -> bool:
        """ê·¸ë£¹ëª…ì¸ì§€ íŒë‹¨"""
        if not text or len(text) < 1:
            return False

        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        try:
            float(text)
            return False
        except ValueError:
            pass

        # í†µê³„ê°’ì¸ ê²½ìš° ì œì™¸
        if any(pattern in text for pattern in ['í‰ê· ', 'í‘œì¤€í¸ì°¨', 'N', 'Std']):
            return False

        # ì˜ë¯¸ìˆëŠ” ê·¸ë£¹ëª… íŒ¨í„´ë“¤
        group_patterns = [
            # ì„±ë³„
            'ë‚¨', 'ì—¬', 'ë‚¨ì', 'ì—¬ì', 'ë‚¨ì„±', 'ì—¬ì„±',
            # ì—°ë ¹
            'ì„¸', 'ëŒ€', 'ë¯¸ë§Œ', 'ì´ìƒ', 'ì´í•˜', 'ì´ˆê³¼',
            # ê²½ë ¥
            'ë…„', 'ê°œì›”', 'ì‹ ì…', 'ê²½í—˜',
            # í•™ë ¥
            'ì¡¸ì—…', 'ê³¼ì •', 'í•™ì‚¬', 'ì„ì‚¬', 'ë°•ì‚¬',
            # ê¸°ê´€
            'ìœ ì¹˜ì›', 'ì–´ë¦°ì´ì§‘', 'êµ­ê³µë¦½', 'ì‚¬ë¦½', 'ë¯¼ê°„',
            # ê¸°íƒ€
            'ëª…', 'ìˆìŒ', 'ì—†ìŒ', 'ì°¸ì—¬', 'ë¶ˆì°¸'
        ]

        return any(pattern in text for pattern in group_patterns) or len(text) <= 10

    def infer_indep_var_from_dependent(self, dep_var: str) -> str:
        """ì¢…ì†ë³€ìˆ˜ë¡œë¶€í„° ë…ë¦½ë³€ìˆ˜ ì¶”ì • (ì„ì‹œ)"""
        # ì¼ë°˜ì ìœ¼ë¡œ ì„±ë³„ë¡œ ë‚˜ëˆ„ëŠ” ê²½ìš°ê°€ ë§ìŒ
        return 'ì„±ë³„'

    def get_variable_mapping(self) -> dict:
        """SPSS ë³€ìˆ˜ì½”ë“œ -> í•œêµ­ì–´ ë§¤í•‘"""
        return {
            'q_1ì„±ë³„': 'ì„±ë³„', 'q1ì„±ë³„': 'ì„±ë³„', 'gender': 'ì„±ë³„',
            'q_2ì—°ë ¹': 'ì—°ë ¹ë²”ì£¼í™”', 'q2ì—°ë ¹': 'ì—°ë ¹ë²”ì£¼í™”', 'age': 'ì—°ë ¹ë²”ì£¼í™”',
            'q_3ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'q3ê²½ë ¥': 'ê²½ë ¥ë²”ì£¼í™”', 'career': 'ê²½ë ¥ë²”ì£¼í™”',
            'q_4ê¸°ê´€': 'ê¸°ê´€ìœ í˜•', 'q4ê¸°ê´€': 'ê¸°ê´€ìœ í˜•', 'institution': 'ê¸°ê´€ìœ í˜•',
            'q_5ë‹´ë‹¹': 'ë‹´ë‹¹ì—°ë ¹', 'q5ë‹´ë‹¹': 'ë‹´ë‹¹ì—°ë ¹', 'class': 'ë‹´ë‹¹ì—°ë ¹',
            'q_6êµì‚¬': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”', 'q6êµì‚¬': 'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”',
            'q_7í•™ë ¥': 'ìµœì¢…í•™ë ¥', 'q7í•™ë ¥': 'ìµœì¢…í•™ë ¥', 'education': 'ìµœì¢…í•™ë ¥',
            'q_8ì „ê³µ': 'ì „ê³µ', 'q8ì „ê³µ': 'ì „ê³µ', 'major': 'ì „ê³µ',
            'í˜„ê²½ë ¥ë²”ì£¼í™”': 'ê²½ë ¥ë²”ì£¼í™”', 'ì—°ë ¹ë²”ì£¼í™”': 'ì—°ë ¹ë²”ì£¼í™”'
        }

    def fallback_pattern_matching(self, df: pd.DataFrame, stats_row: int) -> str:
        """ìµœí›„ ìˆ˜ë‹¨: ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­"""
        try:
            # ì£¼ë³€ì—ì„œ í•œêµ­ì–´ ë³€ìˆ˜ëª… ì°¾ê¸°
            for i in range(max(0, stats_row - 10), min(stats_row + 30, len(df))):
                for col in range(min(3, len(df.columns))):
                    cell = str(df.iloc[i, col]).strip()
                    if self.is_korean_variable_name(cell):
                        return cell

            # ê¸°ë³¸ê°’ ë°˜í™˜
            return 'ë…ë¦½ë³€ìˆ˜'

        except Exception:
            return 'ë…ë¦½ë³€ìˆ˜'

    def comprehensive_group_pattern_matching(self, group_text: str) -> str:
        """í¬ê´„ì  ê·¸ë£¹ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë…ë¦½ë³€ìˆ˜ ì¶”ì •"""
        group = group_text.strip().lower()

        # ğŸ¯ ì´ˆê°•í™”ëœ ê·¸ë£¹ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤
        group_patterns = {
            # === ì—°ë ¹ ê´€ë ¨ íŒ¨í„´ ===
            'ì—°ë ¹ë²”ì£¼í™”': [
                # í•œêµ­ì‹ ì—°ë ¹ í‘œí˜„
                'ì„¸ ë¯¸ë§Œ', 'ì„¸ ì´ìƒ', 'ì„¸ë¯¸ë§Œ', 'ì„¸ì´ìƒ', 'ì„¸ ì´í•˜', 'ì„¸ì´í•˜',
                '20ì„¸', '25ì„¸', '30ì„¸', '35ì„¸', '40ì„¸', '45ì„¸', '50ì„¸', '55ì„¸', '60ì„¸',
                '20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€', '60ëŒ€', '70ëŒ€',
                'ì´ì‹­ëŒ€', 'ì‚¼ì‹­ëŒ€', 'ì‚¬ì‹­ëŒ€', 'ì˜¤ì‹­ëŒ€', 'ìœ¡ì‹­ëŒ€',
                # ì˜ì–´ì‹ ì—°ë ¹ í‘œí˜„
                'under', 'over', 'below', 'above', 'years old', 'age',
                'young', 'middle', 'old', 'elder', 'senior',
                # íŠ¹ìˆ˜ ì—°ë ¹ êµ¬ë¶„
                'ì²­ë…„', 'ì¤‘ë…„', 'ë…¸ë…„', 'ì¥ë…„', 'ì–´ë¦°', 'ë‚˜ì´',
                '10ëŒ€', 'ì²­ì†Œë…„', 'ì„±ì¸', 'ë…¸ì¸', 'ì–´ë¥´ì‹ '
            ],

            # === ê²½ë ¥/ê·¼ë¬´ë…„ìˆ˜ ê´€ë ¨ íŒ¨í„´ ===
            'ê²½ë ¥ë²”ì£¼í™”': [
                # í•œêµ­ì‹ ê²½ë ¥ í‘œí˜„
                'ë…„ ë¯¸ë§Œ', 'ë…„ ì´ìƒ', 'ë…„ë¯¸ë§Œ', 'ë…„ì´ìƒ', 'ë…„ ì´í•˜', 'ë…„ì´í•˜',
                '1ë…„', '2ë…„', '3ë…„', '4ë…„', '5ë…„', '6ë…„', '7ë…„', '8ë…„', '9ë…„', '10ë…„',
                'ë…„ì°¨', 'ì—°ì°¨', 'í•´ì°¨', 'ê°œì›”', 'ì›”',
                # ê²½ë ¥ êµ¬ë¶„ í‘œí˜„
                'ì‹ ì…', 'ì´ˆê¸‰', 'ì¤‘ê¸‰', 'ê³ ê¸‰', 'ìˆ™ë ¨', 'ë² í…Œë‘',
                'ì‹ ê·œ', 'ê²½í—˜ì', 'ìˆ™ë ¨ì', 'ì „ë¬¸ê°€', 'ì„ ì„',
                # ì˜ì–´ì‹ ê²½ë ¥ í‘œí˜„
                'years', 'year', 'experience', 'exp', 'career',
                'beginner', 'junior', 'senior', 'expert', 'veteran',
                'novice', 'experienced', 'skilled'
            ],

            # === ì„±ë³„ ê´€ë ¨ íŒ¨í„´ ===
            'ì„±ë³„': [
                'ë‚¨ì', 'ì—¬ì', 'ë‚¨ì„±', 'ì—¬ì„±', 'ë‚¨', 'ì—¬',
                'male', 'female', 'man', 'woman', 'men', 'women',
                'ë‚¨í•™ìƒ', 'ì—¬í•™ìƒ', 'ë‚¨êµì‚¬', 'ì—¬êµì‚¬',
                'ì•„ë²„ì§€', 'ì–´ë¨¸ë‹ˆ', 'ì•„ë¹ ', 'ì—„ë§ˆ'
            ],

            # === í•™ë ¥/êµìœ¡ ê´€ë ¨ íŒ¨í„´ ===
            'ìµœì¢…í•™ë ¥': [
                # í•™ìœ„ ê´€ë ¨
                'ì¡¸ì—…', 'ìˆ˜ë£Œ', 'ì¤‘í‡´', 'ì¬í•™',
                'í•™ì‚¬', 'ì„ì‚¬', 'ë°•ì‚¬', 'ì „ë¬¸í•™ì‚¬',
                'ëŒ€í•™ì›', 'ëŒ€í•™êµ', 'ì „ë¬¸ëŒ€í•™', 'ì „ë¬¸ëŒ€', '4ë…„ì œ', '2ë…„ì œ',
                'ê³ ë“±í•™êµ', 'ê³ êµ', 'ì¤‘í•™êµ', 'ì¤‘í•™', 'ì´ˆë“±í•™êµ', 'ì´ˆë“±',
                # íŠ¹ìˆ˜ êµìœ¡ê³¼ì •
                'ë³´ìœ¡êµì‚¬ ì–‘ì„±ê³¼ì •', 'ì–‘ì„±ê³¼ì •', 'ì§ì—…í›ˆë ¨',
                'ì‚¬ì´ë²„ëŒ€í•™', 'ë°©ì†¡ëŒ€í•™', 'í‰ìƒêµìœ¡',
                # ì˜ì–´ì‹ í‘œí˜„
                'bachelor', 'master', 'doctor', 'phd', 'college', 'university',
                'graduate', 'undergraduate', 'diploma', 'certificate'
            ],

            # === ì „ê³µ ê´€ë ¨ íŒ¨í„´ ===
            'ì „ê³µ': [
                # êµìœ¡ ê´€ë ¨ ì „ê³µ
                'ìœ ì•„êµìœ¡ê³¼', 'ì•„ë™í•™ê³¼', 'ë³´ìœ¡ê´€ë ¨í•™ê³¼', 'êµìœ¡í•™ê³¼',
                'ìœ ì•„êµìœ¡', 'ì•„ë™í•™', 'ë³´ìœ¡í•™', 'êµìœ¡í•™',
                'ì‚¬íšŒë³µì§€í•™ê³¼', 'ì‹¬ë¦¬í•™ê³¼', 'ìƒë‹´í•™ê³¼',
                # ì¼ë°˜ ì „ê³µ í‘œí˜„
                'ì „ê³µ', 'í•™ê³¼', 'ê³¼', 'í•™ë¶€', 'ê³„ì—´',
                'ì¸ë¬¸ê³„', 'ì´ê³µê³„', 'ì˜ˆì²´ëŠ¥ê³„', 'ìƒê²½ê³„',
                # ì˜ì–´ì‹ ì „ê³µ í‘œí˜„
                'major', 'department', 'faculty', 'school',
                'humanities', 'science', 'engineering', 'business',
                'ê¸°íƒ€'  # ê¸°íƒ€ ì „ê³µ
            ],

            # === ê¸°ê´€/ì¡°ì§ ê´€ë ¨ íŒ¨í„´ ===
            'ê¸°ê´€ìœ í˜•': [
                # ìœ ì•„êµìœ¡ê¸°ê´€
                'ìœ ì¹˜ì›', 'ì–´ë¦°ì´ì§‘', 'ë³´ìœ¡ì›', 'ì–´ë¦°ì´ì§‘',
                'êµ­ê³µë¦½ìœ ì¹˜ì›', 'ì‚¬ë¦½ìœ ì¹˜ì›', 'ê³µë¦½ìœ ì¹˜ì›', 'ì‚¬ì‚¬ë¦½ìœ ì¹˜ì›',
                'êµ­ê³µë¦½ì–´ë¦°ì´ì§‘', 'ë¯¼ê°„ì–´ë¦°ì´ì§‘', 'ê°€ì •ì–´ë¦°ì´ì§‘', 'ë²•ì¸ì–´ë¦°ì´ì§‘',
                'ì§ì¥ì–´ë¦°ì´ì§‘', 'í˜‘ë™ì–´ë¦°ì´ì§‘', 'ë¶€ëª¨í˜‘ë™ì–´ë¦°ì´ì§‘',
                # ì¼ë°˜ ê¸°ê´€
                'ê³µê³µê¸°ê´€', 'ë¯¼ê°„ê¸°ê´€', 'ì •ë¶€ê¸°ê´€', 'ì§€ìì²´',
                'ëŒ€ê¸°ì—…', 'ì¤‘ì†Œê¸°ì—…', 'ë²¤ì²˜ê¸°ì—…', 'ìŠ¤íƒ€íŠ¸ì—…',
                'ë³‘ì›', 'ì˜ë£Œê¸°ê´€', 'í´ë¦¬ë‹‰', 'ìš”ì–‘ì›',
                # ì˜ì–´ì‹ í‘œí˜„
                'public', 'private', 'government', 'corporate',
                'hospital', 'clinic', 'company', 'organization'
            ],

            # === ë‹´ë‹¹ì—°ë ¹/í•™ê¸‰ ê´€ë ¨ íŒ¨í„´ ===
            'ë‹´ë‹¹ì—°ë ¹': [
                # ë‹´ë‹¹ ì—°ë ¹
                'ë§Œ3ì„¸', 'ë§Œ4ì„¸', 'ë§Œ5ì„¸', 'ë§Œ 3ì„¸', 'ë§Œ 4ì„¸', 'ë§Œ 5ì„¸',
                '3ì„¸', '4ì„¸', '5ì„¸', '6ì„¸', '7ì„¸',
                'ì˜ì•„', 'ìœ ì•„', 'ì–´ë¦°ì´',
                'ì˜ì•„ë°˜', 'ìœ ì•„ë°˜', 'í˜¼í•©ì—°ë ¹', 'í˜¼í•©ë°˜',
                '0ì„¸ë°˜', '1ì„¸ë°˜', '2ì„¸ë°˜', 'ëˆ„ë¦¬ë°˜',
                # ì˜ì–´ì‹ í‘œí˜„
                'infant', 'toddler', 'preschool', 'kindergarten',
                'mixed age', 'multi age'
            ],

            # === êµì‚¬ìˆ˜/ì¸ì› ê´€ë ¨ íŒ¨í„´ ===
            'í•™ê¸‰êµì‚¬ìˆ˜ë²”ì£¼í™”': [
                '1ëª…', '2ëª…', '3ëª…', '4ëª…', '5ëª…', '6ëª…', '7ëª…', '8ëª…', '9ëª…', '10ëª…',
                'ëª…', 'ì¸', 'ì‚¬ëŒ',
                'í•œëª…', 'ë‘ëª…', 'ì„¸ëª…', 'ë„¤ëª…', 'ë‹¤ì„¯ëª…',
                'ì¼ëª…', 'ì´ëª…', 'ì‚¼ëª…', 'ì‚¬ëª…', 'ì˜¤ëª…',
                '1ì¸', '2ì¸', '3ì¸', '4ì¸', '5ì¸',
                'ë‹¨ë…', 'í˜‘ë ¥', 'íŒ€í‹°ì¹­', 'ê³µë™',
                'ë‹´ì„', 'ë¶€ë‹´ì„', 'ë³´ì¡°',
                # ì˜ì–´ì‹ í‘œí˜„
                'teacher', 'staff', 'instructor', 'educator',
                'single', 'multiple', 'team', 'co-teaching'
            ],

            # === ì§€ì—­ ê´€ë ¨ íŒ¨í„´ ===
            'ì§€ì—­': [
                # ê´‘ì—­ì‹œë„
                'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…',
                'ê²½ê¸°', 'ê°•ì›', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼',
                'ìˆ˜ë„ê¶Œ', 'ì˜ë‚¨ê¶Œ', 'í˜¸ë‚¨ê¶Œ', 'ì¶©ì²­ê¶Œ', 'ê°•ì›ê¶Œ',
                # ì‹œêµ°êµ¬
                'ì‹œ', 'êµ°', 'êµ¬', 'ì', 'ë©´', 'ë™', 'ë¦¬',
                'íŠ¹ë³„ì‹œ', 'ê´‘ì—­ì‹œ', 'íŠ¹ë³„ìì¹˜ì‹œ', 'íŠ¹ë³„ìì¹˜ë„',
                # ì¼ë°˜ ì§€ì—­ í‘œí˜„
                'ë„ì‹¬', 'ì‹œë‚´', 'ì‹œì™¸', 'êµì™¸', 'ë†ì´Œ', 'ì–´ì´Œ', 'ì‚°ì´Œ',
                'ì‹ ë„ì‹œ', 'êµ¬ë„ì‹¬', 'ë²ˆí™”ê°€', 'ì£¼íƒê°€',
                # ì˜ì–´ì‹ í‘œí˜„
                'urban', 'rural', 'suburban', 'metropolitan',
                'downtown', 'city', 'town', 'village'
            ],

            # === ì†Œë“/ê¸‰ì—¬ ê´€ë ¨ íŒ¨í„´ ===
            'ì†Œë“ìˆ˜ì¤€': [
                # ì†Œë“ êµ¬ê°„
                'ë§Œì›', 'ì²œë§Œì›', 'ì–µì›', 'ì›',
                '100ë§Œì›', '200ë§Œì›', '300ë§Œì›', '400ë§Œì›', '500ë§Œì›',
                'ì´í•˜', 'ì´ìƒ', 'ë¯¸ë§Œ', 'ì´ˆê³¼',
                # ì†Œë“ ìˆ˜ì¤€
                'ì €ì†Œë“', 'ì¤‘ì†Œë“', 'ê³ ì†Œë“', 'ìƒìœ„ì†Œë“', 'í•˜ìœ„ì†Œë“',
                'ìµœì €ì„ê¸ˆ', 'í‰ê· ì„ê¸ˆ', 'ê³ ì•¡ì—°ë´‰',
                # ì˜ì–´ì‹ í‘œí˜„
                'low income', 'middle income', 'high income',
                'salary', 'wage', 'income', 'earnings'
            ],

            # === ê²°í˜¼/ê°€ì¡± ê´€ë ¨ íŒ¨í„´ ===
            'ê²°í˜¼ìƒíƒœ': [
                'ë¯¸í˜¼', 'ê¸°í˜¼', 'ì´í˜¼', 'ë³„ê±°', 'ì‚¬ë³„', 'ì¬í˜¼',
                'ë…ì‹ ', 'ì‹±ê¸€', 'ì»¤í”Œ', 'ë¶€ë¶€', 'ë°°ìš°ì',
                'ê²°í˜¼', 'í˜¼ì¸', 'ë™ê±°', 'ì•½í˜¼',
                # ì˜ì–´ì‹ í‘œí˜„
                'single', 'married', 'divorced', 'separated', 'widowed',
                'unmarried', 'spouse', 'partner'
            ],

            # === ìë…€ ê´€ë ¨ íŒ¨í„´ ===
            'ìë…€ìˆ˜': [
                'ë¬´ìë…€', '1ìë…€', '2ìë…€', '3ìë…€', '4ìë…€', 'ë‹¤ìë…€',
                'ì™¸ë™', 'ë‘˜ì§¸', 'ì…‹ì§¸', 'ë§‰ë‚´', 'ì²«ì§¸',
                'ì•„ë“¤', 'ë”¸', 'ë‚¨ì•„', 'ì—¬ì•„',
                'ìë…€ì—†ìŒ', 'ìë…€ìˆìŒ',
                # ì˜ì–´ì‹ í‘œí˜„
                'no children', 'one child', 'two children', 'multiple children',
                'son', 'daughter', 'kids', 'children'
            ],

            # === ì§ê¸‰/ì§ìœ„ ê´€ë ¨ íŒ¨í„´ ===
            'ì§ê¸‰': [
                # ì¼ë°˜ ì§ê¸‰
                'ì‚¬ì›', 'ëŒ€ë¦¬', 'ê³¼ì¥', 'ì°¨ì¥', 'ë¶€ì¥', 'ì´ì‚¬', 'ìƒë¬´', 'ì „ë¬´', 'ë¶€ì‚¬ì¥', 'ì‚¬ì¥',
                'ì£¼ì„', 'ì„ ì„', 'ì±…ì„', 'ìˆ˜ì„', 'ì „ë¬¸', 'íŠ¹ê¸‰',
                'ì¸í„´', 'ìˆ˜ìŠµ', 'ì •ê·œì§', 'ê³„ì•½ì§', 'ì„ì‹œì§',
                # êµìœ¡ ê´€ë ¨ ì§ê¸‰
                'ì›ì¥', 'ì›ê°', 'ì£¼ì„êµì‚¬', 'ë‹´ì„êµì‚¬', 'ë¶€ë‹´ì„êµì‚¬',
                'ìˆ˜ì„êµì‚¬', 'êµê°', 'êµì¥', 'ë³´ì¡°êµì‚¬',
                # ì˜ë£Œ ê´€ë ¨ ì§ê¸‰
                'ì „ë¬¸ì˜', 'ë ˆì§€ë˜íŠ¸', 'ì¸í„´', 'ê°„í˜¸ì‚¬', 'ê°„í˜¸ì¥',
                'ìˆ˜ê°„í˜¸ì‚¬', 'ì±…ì„ê°„í˜¸ì‚¬', 'ì£¼ì„ê°„í˜¸ì‚¬',
                # ì˜ì–´ì‹ í‘œí˜„
                'manager', 'director', 'supervisor', 'coordinator',
                'specialist', 'expert', 'assistant', 'associate'
            ],

            # === ê·¼ë¬´í˜•íƒœ ê´€ë ¨ íŒ¨í„´ ===
            'ê·¼ë¬´í˜•íƒœ': [
                'ì •ê·œì§', 'ë¹„ì •ê·œì§', 'ê³„ì•½ì§', 'ì„ì‹œì§', 'íŒŒê²¬ì§',
                'ì‹œê°„ì œ', 'ì „ì¼ì œ', 'íŒŒíŠ¸íƒ€ì„', 'í’€íƒ€ì„',
                'ì£¼ê°„ê·¼ë¬´', 'ì•¼ê°„ê·¼ë¬´', 'êµëŒ€ê·¼ë¬´', 'ì‹œí”„íŠ¸',
                'ì¬íƒê·¼ë¬´', 'ì›ê²©ê·¼ë¬´', 'ì¶œì¥', 'íŒŒê²¬',
                # ì˜ì–´ì‹ í‘œí˜„
                'full time', 'part time', 'contract', 'temporary',
                'permanent', 'freelance', 'remote', 'shift'
            ],

            # === ë§Œì¡±ë„ ê´€ë ¨ íŒ¨í„´ ===
            'ë§Œì¡±ë„': [
                'ë§¤ìš°ë¶ˆë§Œ', 'ë¶ˆë§Œ', 'ë³´í†µ', 'ë§Œì¡±', 'ë§¤ìš°ë§Œì¡±',
                'ì „í˜€', 'ê±°ì˜', 'ì•½ê°„', 'ìƒë‹¹íˆ', 'ë§¤ìš°',
                '1ì ', '2ì ', '3ì ', '4ì ', '5ì ',
                'ë‚®ìŒ', 'ë†’ìŒ', 'ì¤‘ê°„',
                # ì˜ì–´ì‹ í‘œí˜„
                'very dissatisfied', 'dissatisfied', 'neutral', 'satisfied', 'very satisfied',
                'low', 'medium', 'high', 'excellent', 'poor'
            ],

            # === ì°¸ì—¬/ì´ìš© ê´€ë ¨ íŒ¨í„´ ===
            'ì°¸ì—¬ì—¬ë¶€': [
                'ì°¸ì—¬', 'ë¶ˆì°¸', 'ì°¸ì„', 'ë¶ˆì°¸ì„', 'ì¶œì„', 'ê²°ì„',
                'ì´ìš©', 'ë¯¸ì´ìš©', 'ì‚¬ìš©', 'ë¯¸ì‚¬ìš©', 'í™œìš©', 'ë¯¸í™œìš©',
                'ê²½í—˜', 'ë¯¸ê²½í—˜', 'ìˆ˜ê°•', 'ë¯¸ìˆ˜ê°•',
                'ìˆìŒ', 'ì—†ìŒ', 'í•œë‹¤', 'ì•ˆí•œë‹¤',
                # ì˜ì–´ì‹ í‘œí˜„
                'participate', 'not participate', 'attend', 'not attend',
                'use', 'not use', 'experience', 'no experience'
            ]
        }

        # íŒ¨í„´ ë§¤ì¹­ ì‹¤í–‰ (ê¸´ íŒ¨í„´ë¶€í„° ìš°ì„  ë§¤ì¹­)
        for var_type, patterns in group_patterns.items():
            # íŒ¨í„´ì„ ê¸¸ì´ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ íŒ¨í„´ ìš°ì„ )
            sorted_patterns = sorted(patterns, key=len, reverse=True)
            for pattern in sorted_patterns:
                if pattern in group:
                    return var_type

        return None

    def extract_ttest_analysis(self, df: pd.DataFrame, pair: Dict) -> None:
        """Tê²€ì • ë¶„ì„ ì™„ì „ ì¶”ì¶œ - ê°•í™”ëœ ìœ ì—°ì„±"""
        try:
            stats_row = pair['stats_table']['row']
            results_row = pair['results_table']['row']

            # 1. ì§‘ë‹¨í†µê³„ëŸ‰ ì¶”ì¶œ - ë” ìœ ì—°í•œ ë°©ì‹
            groups_data = {}

            # ê°€ëŠ¥í•œ ëª¨ë“  ì¢…ì†ë³€ìˆ˜ ì°¾ê¸°
            possible_dep_vars = set()
            for i in range(stats_row, min(stats_row + 50, len(df))):
                for col in range(min(3, len(df.columns))):
                    cell_val = str(df.iloc[i, col]).strip()
                    if any(pattern in cell_val for pattern in [
                        'í‰ê· ', 'í•©ê³„', 'ì ìˆ˜', 'ì—­ëŸ‰', 'ì‹ ë…', 'ì„±ê³¼', 'ë§Œì¡±'
                    ]) and len(cell_val) > 3:
                        possible_dep_vars.add(cell_val)

            # ê° ì¢…ì†ë³€ìˆ˜ë³„ë¡œ ê·¸ë£¹ ë°ì´í„° ìˆ˜ì§‘
            for dep_var in possible_dep_vars:
                groups_data[dep_var] = []

                for i in range(stats_row + 2, min(stats_row + 30, len(df))):
                    if 'ë…ë¦½í‘œë³¸' in str(df.iloc[i, 0]):
                        break

                    var_cell = str(df.iloc[i, 0]).strip()
                    group_cell = str(df.iloc[i, 1]).strip()

                    # ğŸ¯ ì‹¤ì œ ê·¸ë£¹ëª…ë§Œ ì¸ì‹ (Tê²€ì • ë²„ì „)
                    if dep_var == var_cell and group_cell and self.is_real_group_name(group_cell):
                        # ì²« ë²ˆì§¸ ê·¸ë£¹
                        try:
                            n_col = self.find_number_column(df, i, 'n')
                            mean_col = self.find_number_column(df, i, 'mean')
                            std_col = self.find_number_column(df, i, 'std')

                            if n_col and mean_col and std_col:
                                groups_data[dep_var].append({
                                    'group': group_cell,
                                    'n': int(float(df.iloc[i, n_col])),
                                    'mean': float(df.iloc[i, mean_col]),
                                    'std': float(df.iloc[i, std_col])
                                })

                                self.root.after(0, lambda grp=group_cell:
                                               self.log(f"    âœ… ì‹¤ì œ ê·¸ë£¹ ë°œê²¬: {grp}"))

                                # ë‹¤ìŒ ê·¸ë£¹ ì°¾ê¸°
                                for j in range(i + 1, min(i + 5, len(df))):
                                    next_group = str(df.iloc[j, 1]).strip()
                                    if (next_group and next_group != group_cell and
                                        self.is_real_group_name(next_group)):

                                        groups_data[dep_var].append({
                                            'group': next_group,
                                            'n': int(float(df.iloc[j, n_col])),
                                            'mean': float(df.iloc[j, mean_col]),
                                            'std': float(df.iloc[j, std_col])
                                        })

                                        self.root.after(0, lambda grp=next_group:
                                                       self.log(f"    âœ… ì‹¤ì œ ê·¸ë£¹ ë°œê²¬: {grp}"))
                                        break
                        except (ValueError, IndexError):
                            continue
                        break

            # ë¹ˆ ê·¸ë£¹ ì œê±°
            groups_data = {k: v for k, v in groups_data.items() if v}

            # 2. Tê²€ì • ê²°ê³¼ ì¶”ì¶œ - ë” ìœ ì—°í•œ ë°©ì‹
            test_results = {}

            for var in possible_dep_vars:
                if var in groups_data:  # ê·¸ë£¹ ë°ì´í„°ê°€ ìˆëŠ” ë³€ìˆ˜ë§Œ
                    # Tê²€ì • ê²°ê³¼ í…Œì´ë¸”ì—ì„œ í•´ë‹¹ ë³€ìˆ˜ì˜ ê²°ê³¼ ì°¾ê¸°
                    for i in range(results_row + 1, min(results_row + 30, len(df))):
                        result_var = str(df.iloc[i, 0]).strip()
                        condition = str(df.iloc[i, 1]).strip() if len(df.columns) > 1 else ""

                        if var == result_var or (result_var and var in result_var):
                            try:
                                # Levene ê²€ì • ê¸°ë°˜ ì„ íƒ
                                if 'ê°€ì •í•¨' in condition:
                                    levene_p_col = self.find_p_value_column(df, i, 'levene')
                                    t_col = self.find_number_column(df, i, 't')
                                    p_col = self.find_p_value_column(df, i, 'ttest')

                                    if levene_p_col and t_col and p_col:
                                        levene_p = float(df.iloc[i, levene_p_col])

                                        if levene_p < 0.05:
                                            # ë“±ë¶„ì‚° ê°€ì • ìœ„ë°˜ â†’ ë‹¤ìŒ í–‰ ì‚¬ìš©
                                            next_i = i + 1
                                            if next_i < len(df):
                                                t_val = float(df.iloc[next_i, t_col])
                                                p_val = float(df.iloc[next_i, p_col])
                                                choice = "ê°€ì •í•˜ì§€ì•ŠìŒ"
                                        else:
                                            # ë“±ë¶„ì‚° ê°€ì • ë§Œì¡± â†’ í˜„ì¬ í–‰ ì‚¬ìš©
                                            t_val = float(df.iloc[i, t_col])
                                            p_val = float(df.iloc[i, p_col])
                                            choice = "ê°€ì •í•¨"

                                        test_results[var] = {'t': t_val, 'p': p_val}

                                        self.root.after(0, lambda var=var, choice=choice, t=t_val, p=p_val:
                                                       self.log(f"  ğŸ“Š {var} ({choice}): t={t:.3f}, p={p:.3f}"))
                                        break

                            except (ValueError, IndexError):
                                continue

            # 3. ê²°ê³¼ ì €ì¥
            for var in groups_data:
                if var in test_results:
                    self.all_analyses.append({
                        'indep_var': pair['indep_var'],
                        'dep_var': var,
                        'groups': groups_data[var],
                        'statistic': test_results[var]['t'],
                        'p_value': test_results[var]['p'],
                        'test_type': 't-test'
                    })
                    self.root.after(0, lambda var=var: self.log(f"  âœ… Tê²€ì • ì €ì¥: {var}"))

        except Exception as e:
            self.root.after(0, lambda e=e: self.log(f"  ğŸ’¥ Tê²€ì • ì¶”ì¶œ ì˜¤ë¥˜: {e}", 'error'))

    def find_p_value_column(self, df: pd.DataFrame, row: int, test_type: str) -> Optional[int]:
        """pê°’ì´ ìˆëŠ” ì»¬ëŸ¼ ì°¾ê¸°"""
        try:
            if test_type == 'levene':
                # Levene ê²€ì • pê°’ì€ ë³´í†µ 3-4ë²ˆì§¸ ì»¬ëŸ¼
                search_cols = range(2, min(6, len(df.columns)))
            else:
                # tê²€ì • pê°’ì€ ë³´í†µ ë§ˆì§€ë§‰ ìª½ ì»¬ëŸ¼
                search_cols = range(5, min(len(df.columns), 10))

            for col in search_cols:
                cell_val = str(df.iloc[row, col]).strip()
                if cell_val:
                    try:
                        num_val = float(cell_val)
                        if 0 <= num_val <= 1:  # pê°’ ë²”ìœ„
                            return col
                    except ValueError:
                        continue
            return None
        except:
            return None

    def extract_anova_analysis(self, df: pd.DataFrame, pair: Dict) -> None:
        """ANOVA ë¶„ì„ ì™„ì „ ì¶”ì¶œ - ê°•í™”ëœ ë””ë²„ê¹…"""
        try:
            stats_row = pair['stats_table']['row']
            results_row = pair['results_table']['row']

            self.root.after(0, lambda: self.log(f"  ğŸ“ ê¸°ìˆ í†µê³„ í–‰{stats_row}, ANOVA ê²°ê³¼ í–‰{results_row}"))

            # 1. ê¸°ìˆ í†µê³„ ì¶”ì¶œ - ì™„ì „íˆ ìœ ì—°í•œ ë°©ì‹
            groups_data = {}

            self.root.after(0, lambda: self.log(f"    ğŸ” ê¸°ìˆ í†µê³„ ìŠ¤ìº” ì‹œì‘..."))

            # ê°€ëŠ¥í•œ ëª¨ë“  ì¢…ì†ë³€ìˆ˜ íŒ¨í„´ ì°¾ê¸°
            possible_dep_vars = set()
            for i in range(stats_row, min(stats_row + 100, len(df))):
                for col in range(min(3, len(df.columns))):
                    cell_val = str(df.iloc[i, col]).strip()

                    # ì¢…ì†ë³€ìˆ˜ë¡œ ë³´ì´ëŠ” íŒ¨í„´ë“¤
                    if any(pattern in cell_val for pattern in [
                        'í‰ê· ', 'í•©ê³„', 'ì ìˆ˜', 'ì—­ëŸ‰', 'ì‹ ë…', 'ì„±ê³¼', 'ë§Œì¡±',
                        'average', 'mean', 'total', 'score', 'satisfaction'
                    ]) and len(cell_val) > 3:
                        possible_dep_vars.add(cell_val)

            self.root.after(0, lambda vars=list(possible_dep_vars):
                           self.log(f"    ğŸ“‹ ê°€ëŠ¥í•œ ì¢…ì†ë³€ìˆ˜ë“¤: {vars}"))

            # ê° ì¢…ì†ë³€ìˆ˜ë³„ë¡œ ê·¸ë£¹ ë°ì´í„° ìˆ˜ì§‘
            for dep_var in possible_dep_vars:
                groups_data[dep_var] = []

                # í•´ë‹¹ ë³€ìˆ˜ì˜ ë°ì´í„° í–‰ë“¤ ì°¾ê¸°
                for i in range(stats_row, min(stats_row + 100, len(df))):
                    if 'ANOVA' in str(df.iloc[i, 0]):
                        break

                    # ë³€ìˆ˜ëª…ì´ ë‚˜íƒ€ë‚˜ëŠ” í–‰ ì°¾ê¸°
                    if dep_var in str(df.iloc[i, 0]):
                        # ì´ ë³€ìˆ˜ì˜ ê·¸ë£¹ë“¤ ìˆ˜ì§‘
                        self.root.after(0, lambda var=dep_var: self.log(f"    ğŸ“ {var} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘"))

                        for j in range(i, min(i + 20, len(df))):
                            try:
                                group_name = str(df.iloc[j, 1]).strip() if len(df.columns) > 1 else ""

                                # ğŸ¯ ì‹¤ì œ ê·¸ë£¹ëª…ë§Œ ì¸ì‹ (í†µê³„ìš©ì–´ ì™„ì „ ì œì™¸)
                                if (group_name and group_name != 'ì „ì²´' and group_name != dep_var and
                                    self.is_real_group_name(group_name)):

                                    # ìˆ«ì ë°ì´í„° í™•ì¸
                                    n_col = self.find_number_column(df, j, 'n')
                                    mean_col = self.find_number_column(df, j, 'mean')
                                    std_col = self.find_number_column(df, j, 'std')

                                    if n_col is not None and mean_col is not None and std_col is not None:
                                        n_val = float(df.iloc[j, n_col])
                                        mean_val = float(df.iloc[j, mean_col])
                                        std_val = float(df.iloc[j, std_col])

                                        groups_data[dep_var].append({
                                            'group': group_name,
                                            'n': int(n_val),
                                            'mean': mean_val,
                                            'std': std_val
                                        })

                                        self.root.after(0, lambda var=dep_var, grp=group_name:
                                                       self.log(f"    âœ… {var} - {grp} (ì‹¤ì œ ê·¸ë£¹)"))
                            except (ValueError, IndexError):
                                continue

                        break  # ì´ ë³€ìˆ˜ëŠ” ì²˜ë¦¬ ì™„ë£Œ

            # ë¹ˆ ê·¸ë£¹ ì œê±°
            groups_data = {k: v for k, v in groups_data.items() if v}

            # 2. ANOVA ê²°ê³¼ ì¶”ì¶œ - ì™„ì „íˆ ìœ ì—°í•œ ë°©ì‹
            test_results = {}

            self.root.after(0, lambda: self.log(f"    ğŸ” ANOVA ê²°ê³¼ ìŠ¤ìº” ì‹œì‘..."))

            # ANOVA í…Œì´ë¸”ì—ì„œ Fê°’ê³¼ pê°’ ì°¾ê¸°
            for i in range(results_row, min(results_row + 50, len(df))):
                row_content = " ".join([str(df.iloc[i, col]).strip() for col in range(min(len(df.columns), 10))])

                # ì§‘ë‹¨-ê°„ (Between Groups) í–‰ ì°¾ê¸°
                if any(keyword in row_content for keyword in ['ì§‘ë‹¨-ê°„', 'Between Groups', 'ì§‘ë‹¨ê°„']):
                    # ì´ í–‰ì—ì„œ Fê°’ê³¼ pê°’ ì°¾ê¸°
                    for dep_var in possible_dep_vars:
                        if dep_var in groups_data:  # ê·¸ë£¹ ë°ì´í„°ê°€ ìˆëŠ” ë³€ìˆ˜ë§Œ
                            # Fê°’ê³¼ pê°’ ì°¾ê¸° (ì—¬ëŸ¬ ì»¬ëŸ¼ ì‹œë„)
                            f_val, p_val = self.extract_f_and_p_values(df, i)

                            if f_val is not None and p_val is not None:
                                # ë³€ìˆ˜ëª… ë§¤ì¹­ (ê°€ì¥ ê°€ê¹Œìš´ ìœ„ì¹˜ì˜ ë³€ìˆ˜)
                                closest_var = self.find_closest_variable(df, i, possible_dep_vars)
                                if closest_var:
                                    test_results[closest_var] = {'f': f_val, 'p': p_val}
                                    self.root.after(0, lambda var=closest_var, f=f_val, p=p_val:
                                                   self.log(f"    âœ… ANOVA: {var}, F={f:.3f}, p={p:.6f}"))
                                break

            # 3. ê²°ê³¼ ì €ì¥
            self.root.after(0, lambda: self.log(f"  ğŸ“Š ê¸°ìˆ í†µê³„: {list(groups_data.keys())}"))
            self.root.after(0, lambda: self.log(f"  ğŸ“Š ANOVA ê²°ê³¼: {list(test_results.keys())}"))

            success_count = 0
            for var in groups_data:
                if var in test_results:
                    self.all_analyses.append({
                        'indep_var': pair['indep_var'],
                        'dep_var': var,
                        'groups': groups_data[var],
                        'statistic': test_results[var]['f'],
                        'p_value': test_results[var]['p'],
                        'test_type': 'anova'
                    })
                    self.root.after(0, lambda var=var: self.log(f"  âœ… ì €ì¥ ì„±ê³µ: {var}"))
                    success_count += 1
                else:
                    self.root.after(0, lambda var=var: self.log(f"  âŒ ì €ì¥ ì‹¤íŒ¨: {var}"))

            self.root.after(0, lambda count=success_count: self.log(f"  ğŸ“ˆ ì„±ê³µë¥ : {count}/{len(groups_data)}ê°œ"))

        except Exception as e:
            self.root.after(0, lambda e=e: self.log(f"  ğŸ’¥ ANOVA ì¶”ì¶œ ì˜¤ë¥˜: {e}", 'error'))

    def find_number_column(self, df: pd.DataFrame, row: int, data_type: str) -> Optional[int]:
        """ìˆ«ì ë°ì´í„°ê°€ ìˆëŠ” ì»¬ëŸ¼ ì°¾ê¸°"""
        try:
            for col in range(2, min(len(df.columns), 8)):  # 2ë²ˆì§¸ ì»¬ëŸ¼ë¶€í„° í™•ì¸
                cell_val = str(df.iloc[row, col]).strip()
                if cell_val and cell_val != '':
                    try:
                        float(cell_val)
                        return col
                    except ValueError:
                        continue
            return None
        except:
            return None

    def extract_f_and_p_values(self, df: pd.DataFrame, row: int) -> tuple:
        """Fê°’ê³¼ pê°’ ì¶”ì¶œ"""
        try:
            f_val = None
            p_val = None

            # ì—¬ëŸ¬ ì»¬ëŸ¼ì—ì„œ Fê°’ê³¼ pê°’ ì°¾ê¸°
            for col in range(min(len(df.columns), 10)):
                cell_val = str(df.iloc[row, col]).strip()
                if cell_val and cell_val != '':
                    try:
                        num_val = float(cell_val)
                        if 0 <= num_val <= 1 and p_val is None:  # pê°’ ê°™ì•„ ë³´ì´ëŠ” ê²ƒ
                            p_val = num_val
                        elif num_val > 1 and f_val is None:  # Fê°’ ê°™ì•„ ë³´ì´ëŠ” ê²ƒ
                            f_val = num_val
                    except ValueError:
                        continue

            return f_val, p_val
        except:
            return None, None

    def find_closest_variable(self, df: pd.DataFrame, row: int, possible_vars: set) -> Optional[str]:
        """ê°€ì¥ ê°€ê¹Œìš´ ìœ„ì¹˜ì˜ ë³€ìˆ˜ëª… ì°¾ê¸°"""
        try:
            # í˜„ì¬ í–‰ ìœ„ìª½ì—ì„œ ë³€ìˆ˜ëª… ì°¾ê¸°
            for i in range(row, max(0, row - 20), -1):
                for col in range(min(3, len(df.columns))):
                    cell_val = str(df.iloc[i, col]).strip()
                    if cell_val in possible_vars:
                        return cell_val

            # ëª» ì°¾ìœ¼ë©´ ì²« ë²ˆì§¸ ê°€ëŠ¥í•œ ë³€ìˆ˜ ë°˜í™˜
            return list(possible_vars)[0] if possible_vars else None
        except:
            return None


    def create_perfect_output(self) -> str:
        """ë™ì  ì¢…ì†ë³€ìˆ˜ ê°œìˆ˜ ê¸°ë°˜ OUTPUT í‘œ ìƒì„±"""
        wb = Workbook()
        ws = wb.active
        ws.title = 'OUTPUT'

        # ğŸ¯ ëª¨ë“  ì¢…ì†ë³€ìˆ˜ ë™ì  ì¶”ì¶œ
        dep_vars = []
        if self.all_analyses:
            # ëª¨ë“  ì¢…ì†ë³€ìˆ˜ ìˆ˜ì§‘
            all_dep_vars = list(set([analysis['dep_var'] for analysis in self.all_analyses]))

            # ì„ í˜¸ ìˆœì„œë¡œ ì •ë ¬ (íŠ¹ì • íŒ¨í„´ ìš°ì„ )
            priority_patterns = ['ì—­ëŸ‰', 'ì‹ ë…', 'ì„±ê³¼', 'ë§Œì¡±', 'í‰ê· ', 'í•©ê³„', 'ì ìˆ˜']

            def sort_key(var):
                for i, pattern in enumerate(priority_patterns):
                    if pattern in var:
                        return i
                return len(priority_patterns)

            dep_vars = sorted(all_dep_vars, key=sort_key)

        # ğŸ¯ ì¢…ì†ë³€ìˆ˜ ê°œìˆ˜ì— ë§ì¶° ë™ì  í…Œì´ë¸” ìƒì„±
        dep_count = len(dep_vars) if dep_vars else 1
        self.root.after(0, lambda count=dep_count:
                       self.log(f"ğŸ“‹ ì¢…ì†ë³€ìˆ˜ {count}ê°œ ë°œê²¬, ë™ì  í‘œ ìƒì„±"))

        # ì¢…ì†ë³€ìˆ˜ë³„ë¡œ ë¡œê·¸ ì¶œë ¥
        for i, var in enumerate(dep_vars):
            self.root.after(0, lambda idx=i+1, v=var:
                           self.log(f"  {idx}. {v}"))

        # ë™ì  í—¤ë” ìƒì„±
        self.create_dynamic_headers(ws, dep_vars)

        # ë™ì  ë°ì´í„° ìƒì„±
        self.create_dynamic_data(ws, dep_vars)

        # ë™ì  ìŠ¤íƒ€ì¼ ì ìš©
        self.apply_dynamic_styles(ws, len(dep_vars))

        # ì €ì¥
        output_path = self.generate_output_path()
        wb.save(output_path)
        return output_path

    def create_dynamic_headers(self, ws, dep_vars: list) -> None:
        """ì¢…ì†ë³€ìˆ˜ ê°œìˆ˜ì— ë§ëŠ” ë™ì  í—¤ë” ìƒì„±"""
        if not dep_vars:
            dep_vars = ["ì¢…ì†ë³€ìˆ˜1"]

        # ğŸ¯ ë™ì  ì»¬ëŸ¼ ìˆ˜ ê³„ì‚° (í•˜ë“œì½”ë”© ì œê±°)
        cols_per_var = self.get_columns_per_variable()  # ë™ì ìœ¼ë¡œ ê³„ì‚°ëœ ì»¬ëŸ¼ ìˆ˜

        # ì²« ë²ˆì§¸ í—¤ë” í–‰: ì¢…ì†ë³€ìˆ˜ëª…
        header1 = ['ë…ë¦½ë³€ìˆ˜']
        for i, dep_var in enumerate(dep_vars):
            header1.extend([dep_var] + [''] * (cols_per_var - 1))
        ws.append(header1)

        # ë‘ ë²ˆì§¸ í—¤ë” í–‰: ì»¬ëŸ¼ëª…
        header2 = ['']
        for _ in dep_vars:
            header2.extend(['ê·¸ë£¹', 'N', 'í‰ê· ', 'í‘œì¤€í¸ì°¨', 'í†µê³„ëŸ‰', 'pê°’'])
        ws.append(header2)

        # í—¤ë” ë³‘í•©
        for i, dep_var in enumerate(dep_vars):
            start_col = 2 + i * cols_per_var  # Bë¶€í„° ì‹œì‘ (AëŠ” ë…ë¦½ë³€ìˆ˜)
            end_col = start_col + cols_per_var - 1
            ws.merge_cells(start_row=1, start_column=start_col, end_row=1, end_column=end_col)

    def create_dynamic_data(self, ws, dep_vars: list) -> None:
        """ì¢…ì†ë³€ìˆ˜ ê°œìˆ˜ì— ë§ëŠ” ë™ì  ë°ì´í„° ìƒì„±"""
        if not self.all_analyses:
            # ë¹ˆ ë°ì´í„°ì¸ ê²½ìš°
            row = ['ë°ì´í„° ì—†ìŒ'] + ['ì¶”ì¶œëœ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤'] * len(dep_vars) * 6
            ws.append(row)
            return

        # ë…ë¦½ë³€ìˆ˜ë³„ë¡œ ë°ì´í„° ìƒì„±
        processed_indep_vars = []

        for analysis in self.all_analyses:
            indep_var = analysis['indep_var']

            if indep_var in processed_indep_vars:
                continue

            processed_indep_vars.append(indep_var)

            # ğŸ¯ ì´ ë…ë¦½ë³€ìˆ˜ì˜ ëª¨ë“  ì¢…ì†ë³€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
            indep_var_data = {}
            for a in self.all_analyses:
                if a['indep_var'] == indep_var:
                    indep_var_data[a['dep_var']] = a

            # ìµœëŒ€ ê·¸ë£¹ ìˆ˜ ê³„ì‚°
            max_groups = 0
            for dep_var in dep_vars:
                if dep_var in indep_var_data:
                    max_groups = max(max_groups, len(indep_var_data[dep_var]['groups']))

            # ê·¸ë£¹ë³„ë¡œ í–‰ ìƒì„±
            for group_idx in range(max_groups):
                row = [indep_var if group_idx == 0 else '']

                # ê° ì¢…ì†ë³€ìˆ˜ë³„ë¡œ ë°ì´í„° ì¶”ê°€
                for dep_var in dep_vars:
                    if dep_var in indep_var_data:
                        analysis = indep_var_data[dep_var]

                        if group_idx < len(analysis['groups']):
                            group = analysis['groups'][group_idx]
                            stat_val = round(analysis['statistic'], 3) if group_idx == 0 else ''
                            p_val = self.format_p_value(analysis['p_value']) if group_idx == 0 else ''

                            row.extend([
                                group['group'], group['n'],
                                round(group['mean'], 4), round(group['std'], 5),
                                stat_val, p_val
                            ])
                        else:
                            # ë¹ˆ ë°ì´í„°
                            row.extend(['', '', '', '', '', ''])
                    else:
                        # í•´ë‹¹ ë…ë¦½ë³€ìˆ˜ì— ì´ ì¢…ì†ë³€ìˆ˜ ë°ì´í„°ê°€ ì—†ìŒ
                        row.extend(['', '', '', '', '', ''])

                ws.append(row)

    def apply_dynamic_styles(self, ws, dep_var_count: int) -> None:
        """ë™ì  ìŠ¤íƒ€ì¼ ì ìš©"""
        cols_per_var = self.get_columns_per_variable()  # ë™ì  ì»¬ëŸ¼ ìˆ˜
        total_cols = 1 + dep_var_count * cols_per_var  # ë…ë¦½ë³€ìˆ˜ ì»¬ëŸ¼ + ì¢…ì†ë³€ìˆ˜ë³„ ì»¬ëŸ¼ë“¤

        # í—¤ë” ë³‘í•© ë° ìŠ¤íƒ€ì¼
        header_font = Font(bold=True, size=11)
        center_align = Alignment(horizontal='center', vertical='center')
        header_fill = PatternFill(start_color='DDDDDD', end_color='DDDDDD', fill_type='solid')

        # ë…ë¦½ë³€ìˆ˜ í—¤ë”
        ws['A1'].font = header_font
        ws['A1'].alignment = center_align
        ws['A1'].fill = header_fill

        # ì¢…ì†ë³€ìˆ˜ë³„ í—¤ë”
        for i in range(dep_var_count):
            start_col = 2 + i * cols_per_var
            header_cell = ws.cell(row=1, column=start_col)
            header_cell.font = header_font
            header_cell.alignment = center_align
            header_cell.fill = header_fill

        # ì»¬ëŸ¼ í—¤ë” ìŠ¤íƒ€ì¼ (2ë²ˆì§¸ í–‰)
        for col in range(1, total_cols + 1):
            cell = ws.cell(row=2, column=col)
            cell.font = Font(bold=True, size=10)
            cell.fill = header_fill
            cell.alignment = center_align

        # ë°ì´í„° ì •ë ¬
        for row in range(3, ws.max_row + 1):
            for col in range(1, total_cols + 1):
                ws.cell(row=row, column=col).alignment = center_align

        # ë™ì  ì—´ ë„ˆë¹„ ì„¤ì •
        self.set_dynamic_column_widths(ws, dep_var_count)

        # í…Œë‘ë¦¬
        self.add_borders_to_table(ws, total_cols)

    def set_dynamic_column_widths(self, ws, dep_var_count: int) -> None:
        """ë™ì  ì—´ ë„ˆë¹„ ì„¤ì •"""
        # ë…ë¦½ë³€ìˆ˜ ì»¬ëŸ¼ (A)
        ws.column_dimensions['A'].width = 18

        # ğŸ¯ ë™ì  ì»¬ëŸ¼ ë„ˆë¹„ ê³„ì‚° (í•˜ë“œì½”ë”© ì œê±°)
        col_widths = self.get_column_widths()
        col_letters = 'BCDEFGHIJKLMNOPQRSTUVWXYZ'

        cols_per_var = self.get_columns_per_variable()
        for dep_idx in range(dep_var_count):
            for col_idx in range(cols_per_var):
                col_pos = 1 + dep_idx * cols_per_var + col_idx  # Bë¶€í„° ì‹œì‘
                if col_pos < len(col_letters) and col_idx < len(col_widths):
                    ws.column_dimensions[col_letters[col_pos]].width = col_widths[col_idx]

    def get_column_widths(self) -> list:
        """ë™ì  ì»¬ëŸ¼ ë„ˆë¹„ ê³„ì‚°"""
        # ê·¸ë£¹, N, í‰ê· , í‘œì¤€í¸ì°¨, í†µê³„ëŸ‰, pê°’
        return [15, 8, 12, 12, 10, 10]

    def get_search_range(self, base_type: str) -> int:
        """ê²€ìƒ‰ ë²”ìœ„ ë™ì  ê³„ì‚° (í•˜ë“œì½”ë”© ì œê±°)"""
        search_ranges = {
            'table_area': 100,     # í…Œì´ë¸” ì˜ì—­ ì°¾ê¸°
            'stats_data': 50,      # í†µê³„ ë°ì´í„° ì¶”ì¶œ
            'extended_stats': 200, # í™•ì¥ í†µê³„ ë°ì´í„°
            'group_search': 15,    # ê·¸ë£¹ ê²€ìƒ‰
            'result_search': 30,   # ê²°ê³¼ ê²€ìƒ‰
            'anova_result': 50,    # ANOVA ê²°ê³¼
            'nearby_search': 10,   # ê·¼ì²˜ ë°ì´í„° ê²€ìƒ‰
            'levene_check': 3      # Levene ê²€ì • í™•ì¸
        }
        return search_ranges.get(base_type, 50)  # ê¸°ë³¸ê°’ 50

    def add_borders_to_table(self, ws, total_cols: int) -> None:
        """í…Œì´ë¸”ì— í…Œë‘ë¦¬ ì¶”ê°€"""
        thin = Border(
            left=Side(style='thin'), right=Side(style='thin'),
            top=Side(style='thin'), bottom=Side(style='thin')
        )

        for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=total_cols):
            for cell in row:
                cell.border = thin

    def format_p_value(self, p_val: float) -> str:
        """pê°’ í˜•ì‹í™”"""
        if p_val < 0.001:
            return "0.000"
        else:
            return f"{p_val:.3f}"

    def generate_output_path(self) -> str:
        """ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        try:
            base_name = os.path.splitext(self.file_path)[0]
            output_path = f"{base_name}_OUTPUT.xlsx"

            counter = 1
            while os.path.exists(output_path):
                output_path = f"{base_name}_OUTPUT_{counter}.xlsx"
                counter += 1

            return output_path
        except:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            return f"SPSS_OUTPUT_{timestamp}.xlsx"

    def apply_styles(self, ws) -> None:
        """ìŠ¤íƒ€ì¼ ì ìš©"""
        # í—¤ë” ë³‘í•©
        ws.merge_cells('A1:F1')
        ws.merge_cells('G1:L1')

        # í°íŠ¸ ë° ì •ë ¬
        header_font = Font(bold=True, size=11)
        center_align = Alignment(horizontal='center', vertical='center')

        ws['A1'].font = header_font
        ws['A1'].alignment = center_align
        ws['G1'].font = header_font
        ws['G1'].alignment = center_align

        # ì»¬ëŸ¼ í—¤ë” ìŠ¤íƒ€ì¼
        header_fill = PatternFill(start_color='DDDDDD', end_color='DDDDDD', fill_type='solid')
        for col in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']:
            cell = ws[f'{col}2']
            cell.font = Font(bold=True, size=10)
            cell.fill = header_fill
            cell.alignment = center_align

        # ë°ì´í„° ì •ë ¬
        for row in range(3, ws.max_row + 1):
            for col in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']:
                ws[f'{col}{row}'].alignment = center_align

        # ì—´ ë„ˆë¹„
        widths = {'A': 15, 'B': 12, 'C': 8, 'D': 10, 'E': 12, 'F': 10, 'G': 8,
                 'H': 12, 'I': 8, 'J': 10, 'K': 12, 'L': 10}
        for col, width in widths.items():
            ws.column_dimensions[col].width = width

        # í…Œë‘ë¦¬
        thin = Border(
            left=Side(style='thin'), right=Side(style='thin'),
            top=Side(style='thin'), bottom=Side(style='thin')
        )

        for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=12):
            for cell in row:
                cell.border = thin

    def open_file(self, file_path: str) -> None:
        """íŒŒì¼ ì—´ê¸°"""
        try:
            if sys.platform == 'darwin':
                os.system(f'open "{file_path}"')
            elif sys.platform == 'win32':
                os.startfile(file_path)
            else:
                os.system(f'xdg-open "{file_path}"')
        except:
            pass

def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜"""
    root = tk.Tk()
    SPSSAnalysisExtractor(root)
    root.mainloop()

if __name__ == "__main__":
    main()